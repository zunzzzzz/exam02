{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE2405_Exam_2_Part_2_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI1ebUOX16FD",
        "colab_type": "text"
      },
      "source": [
        "# EE2405 Embedded System Lab Exam #2 Part 2\n",
        "\n",
        "**Please click on \"Open in playground\" at the upper-left corner to create a copy for you.**\n",
        "\n",
        "---\n",
        "\n",
        "**Please fill in correct statements in the right of the codes to finish the scripts.**  \n",
        "Data sample is generated with a quadratic function and we will train a regression model to fit the data.  \n",
        "And we convert and interpret the trained model with a Tensorflow lite APIs.\n",
        "\n",
        "You can run the script again after you fill all the blank to check the outputs.\n",
        "\n",
        "---\n",
        "\n",
        "The Method to Download the Jupyter Notebook:  \n",
        "File > Download .ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC3FqFF1zRJW",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhRpD2SsyQrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow is an open source machine learning library\n",
        "import tensorflow as tf\n",
        "# Numpy is a math library\n",
        "import numpy as np\n",
        "# Matplotlib is a graphing library\n",
        "import matplotlib.pyplot as plt\n",
        "# math is Python's math library\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YztOxOMy0eUB",
        "colab_type": "text"
      },
      "source": [
        "## Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgApv0fcwU3I",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "5c5c84a2-e30b-42a6-ac73-05df17a85130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# We'll generate this many sample datapoints\n",
        "############################################################\n",
        "#@markdown Please fill in the number of samples (the sample should be large enough, but not too large for computation).\n",
        "SAMPLES =  1000#@param {type:\"number\"}\n",
        "############################################################\n",
        "\n",
        "\n",
        "############################################################\n",
        "#@markdown Please fill in your student id, which is the random seed.\n",
        "student_id = 106060024 #@param {type:\"number\"}\n",
        "np.random.seed(student_id)\n",
        "############################################################\n",
        "\n",
        "# Generate a uniformly distributed set of random numbers\n",
        "# in the range from 0 to 10\n",
        "x_values = np.random.uniform(low=0, high=10, size=SAMPLES)\n",
        "\n",
        "# Shuffle the values to guarantee they're not in order\n",
        "np.random.shuffle(x_values)\n",
        "\n",
        "############################################################\n",
        "#@markdown Please fill in the statement to generate `y_values` with a quadratic function `y = x^2-5x+1`?\n",
        "script = \"y_values = x_values ** 2 - 5 * x_values + 1\" #@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################\n",
        "\n",
        "# Plot our data.\n",
        "# The 'b.' argument tells the library to print blue dots.\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGVnrxG10nHh",
        "colab_type": "text"
      },
      "source": [
        "## Add some noise\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR7y-_3_x-Lz",
        "colab_type": "code",
        "outputId": "d75dfa44-8a2e-435b-cd2c-60eb8ebce2d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Add a small random number to each y value\n",
        "y_values += np.random.randn(*y_values.shape)\n",
        "\n",
        "# Plot our data\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI4ZI4Wv4B_y",
        "colab_type": "text"
      },
      "source": [
        "## Split our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1zguEyz393e",
        "colab_type": "code",
        "outputId": "3253cb40-286a-456a-ad9a-03aed995464b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
        "# will be used for validation. Calculate the indices of each section.\n",
        "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "# Use np.split to chop our data into three parts.\n",
        "# The second argument to np.split is an array of indices where the data will be\n",
        "# split. We provide two indices, so the data will be divided into three chunks.\n",
        "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# Double check that our splits add up correctly\n",
        "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
        "\n",
        "# Plot the data in each partition in different colors:\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JggfIuHp4PCy",
        "colab_type": "text"
      },
      "source": [
        "## Design a model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nty9IWi-4QhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll use Keras to create a simple model architecture\n",
        "from tensorflow.keras import layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "\n",
        "# The new second layer may help the network learn more complex representations\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "# Compile the model using a standard optimizer and loss function for regression\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMeLOUmx4VY7",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJiV9Aee4ZTb",
        "colab_type": "code",
        "outputId": "73ef3bcd-22c8-4d28-ed67-fa15a63bda8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model on our training data while validating on our validation set\n",
        "model.fit(x_train, y_train, epochs=1000, batch_size=16,\n",
        "          validation_data=(x_validate, y_validate))\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 312.3936 - mae: 12.0405 - val_loss: 211.2410 - val_mae: 10.0407\n",
            "Epoch 2/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 280.4402 - mae: 11.5868 - val_loss: 188.8235 - val_mae: 9.6335\n",
            "Epoch 3/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 247.7617 - mae: 11.1635 - val_loss: 165.8795 - val_mae: 9.2546\n",
            "Epoch 4/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 218.7400 - mae: 10.7198 - val_loss: 145.0160 - val_mae: 9.0048\n",
            "Epoch 5/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 191.0009 - mae: 10.3294 - val_loss: 125.6466 - val_mae: 8.8004\n",
            "Epoch 6/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 166.1146 - mae: 9.9725 - val_loss: 110.4359 - val_mae: 8.6690\n",
            "Epoch 7/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 142.9785 - mae: 9.6622 - val_loss: 102.0726 - val_mae: 8.7669\n",
            "Epoch 8/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 129.2465 - mae: 9.5680 - val_loss: 99.6402 - val_mae: 8.8624\n",
            "Epoch 9/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 123.3321 - mae: 9.5101 - val_loss: 99.4538 - val_mae: 8.9467\n",
            "Epoch 10/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 119.7669 - mae: 9.4844 - val_loss: 98.9309 - val_mae: 8.9354\n",
            "Epoch 11/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 117.5533 - mae: 9.4113 - val_loss: 98.6159 - val_mae: 8.9213\n",
            "Epoch 12/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 115.4789 - mae: 9.3661 - val_loss: 96.3577 - val_mae: 8.8020\n",
            "Epoch 13/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 114.0366 - mae: 9.2394 - val_loss: 95.3259 - val_mae: 8.7455\n",
            "Epoch 14/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 111.8097 - mae: 9.1655 - val_loss: 94.3901 - val_mae: 8.6900\n",
            "Epoch 15/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 109.6594 - mae: 9.1216 - val_loss: 91.4915 - val_mae: 8.5393\n",
            "Epoch 16/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 108.0374 - mae: 8.9953 - val_loss: 90.2119 - val_mae: 8.4672\n",
            "Epoch 17/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 106.1615 - mae: 8.8874 - val_loss: 88.8497 - val_mae: 8.3897\n",
            "Epoch 18/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 104.0875 - mae: 8.8109 - val_loss: 86.3547 - val_mae: 8.2553\n",
            "Epoch 19/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 102.8247 - mae: 8.6762 - val_loss: 85.4419 - val_mae: 8.2026\n",
            "Epoch 20/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 101.4183 - mae: 8.6277 - val_loss: 83.5266 - val_mae: 8.0974\n",
            "Epoch 21/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 98.7383 - mae: 8.5083 - val_loss: 82.3424 - val_mae: 8.0276\n",
            "Epoch 22/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 97.0865 - mae: 8.4182 - val_loss: 81.1606 - val_mae: 7.9542\n",
            "Epoch 23/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 94.4108 - mae: 8.3446 - val_loss: 78.5666 - val_mae: 7.8182\n",
            "Epoch 24/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 92.3104 - mae: 8.2155 - val_loss: 75.8017 - val_mae: 7.6643\n",
            "Epoch 25/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 89.4363 - mae: 8.0617 - val_loss: 74.3237 - val_mae: 7.5735\n",
            "Epoch 26/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 87.0416 - mae: 7.9432 - val_loss: 72.5869 - val_mae: 7.4664\n",
            "Epoch 27/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 84.5001 - mae: 7.8320 - val_loss: 69.9075 - val_mae: 7.3124\n",
            "Epoch 28/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 81.8059 - mae: 7.6871 - val_loss: 66.7391 - val_mae: 7.1298\n",
            "Epoch 29/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 79.6636 - mae: 7.5505 - val_loss: 64.9202 - val_mae: 7.0164\n",
            "Epoch 30/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 76.9766 - mae: 7.3800 - val_loss: 63.9621 - val_mae: 6.9433\n",
            "Epoch 31/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 74.8653 - mae: 7.2843 - val_loss: 61.2733 - val_mae: 6.7774\n",
            "Epoch 32/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 71.3256 - mae: 7.1143 - val_loss: 58.8340 - val_mae: 6.6192\n",
            "Epoch 33/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 68.8677 - mae: 6.9596 - val_loss: 55.4020 - val_mae: 6.4026\n",
            "Epoch 34/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 65.9871 - mae: 6.7813 - val_loss: 53.5535 - val_mae: 6.2720\n",
            "Epoch 35/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 63.1872 - mae: 6.6211 - val_loss: 51.7779 - val_mae: 6.1392\n",
            "Epoch 36/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 60.1544 - mae: 6.4564 - val_loss: 47.8553 - val_mae: 5.8836\n",
            "Epoch 37/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 57.5916 - mae: 6.2635 - val_loss: 46.4134 - val_mae: 5.7676\n",
            "Epoch 38/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 54.0278 - mae: 6.0939 - val_loss: 43.7954 - val_mae: 5.5767\n",
            "Epoch 39/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 51.2342 - mae: 5.8691 - val_loss: 42.1488 - val_mae: 5.4464\n",
            "Epoch 40/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 48.5108 - mae: 5.7277 - val_loss: 38.6719 - val_mae: 5.1890\n",
            "Epoch 41/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 45.4839 - mae: 5.5023 - val_loss: 38.1428 - val_mae: 5.1324\n",
            "Epoch 42/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 42.5083 - mae: 5.3646 - val_loss: 33.3704 - val_mae: 4.7598\n",
            "Epoch 43/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 39.9779 - mae: 5.1154 - val_loss: 32.5560 - val_mae: 4.6853\n",
            "Epoch 44/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 37.0505 - mae: 4.9627 - val_loss: 28.9277 - val_mae: 4.3706\n",
            "Epoch 45/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 34.5296 - mae: 4.7168 - val_loss: 27.5918 - val_mae: 4.2515\n",
            "Epoch 46/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 31.1622 - mae: 4.5160 - val_loss: 24.0624 - val_mae: 3.9130\n",
            "Epoch 47/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 28.7271 - mae: 4.2911 - val_loss: 21.9563 - val_mae: 3.7144\n",
            "Epoch 48/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 26.0601 - mae: 4.0801 - val_loss: 19.7621 - val_mae: 3.4973\n",
            "Epoch 49/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 23.9482 - mae: 3.8562 - val_loss: 19.2764 - val_mae: 3.4768\n",
            "Epoch 50/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 21.7734 - mae: 3.7026 - val_loss: 16.6938 - val_mae: 3.1939\n",
            "Epoch 51/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 20.0490 - mae: 3.4642 - val_loss: 16.3752 - val_mae: 3.1927\n",
            "Epoch 52/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 17.9464 - mae: 3.3240 - val_loss: 13.4211 - val_mae: 2.8168\n",
            "Epoch 53/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 16.4843 - mae: 3.1116 - val_loss: 12.3551 - val_mae: 2.7225\n",
            "Epoch 54/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 14.8696 - mae: 2.9451 - val_loss: 11.2426 - val_mae: 2.5876\n",
            "Epoch 55/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 13.3672 - mae: 2.7765 - val_loss: 10.1808 - val_mae: 2.4474\n",
            "Epoch 56/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 12.1847 - mae: 2.6673 - val_loss: 9.1814 - val_mae: 2.3111\n",
            "Epoch 57/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 11.1034 - mae: 2.5208 - val_loss: 9.3208 - val_mae: 2.3970\n",
            "Epoch 58/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9945 - mae: 2.4142 - val_loss: 8.3049 - val_mae: 2.2541\n",
            "Epoch 59/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0131 - mae: 2.3011 - val_loss: 6.9189 - val_mae: 1.9814\n",
            "Epoch 60/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.3146 - mae: 2.2082 - val_loss: 6.3864 - val_mae: 1.8954\n",
            "Epoch 61/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.7130 - mae: 2.1315 - val_loss: 6.5231 - val_mae: 1.9853\n",
            "Epoch 62/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.0459 - mae: 2.0319 - val_loss: 6.0274 - val_mae: 1.9069\n",
            "Epoch 63/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.5292 - mae: 1.9457 - val_loss: 5.5791 - val_mae: 1.8304\n",
            "Epoch 64/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.0536 - mae: 1.8888 - val_loss: 4.6878 - val_mae: 1.6222\n",
            "Epoch 65/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.5072 - mae: 1.7931 - val_loss: 4.4606 - val_mae: 1.5998\n",
            "Epoch 66/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.1163 - mae: 1.7359 - val_loss: 4.0059 - val_mae: 1.4947\n",
            "Epoch 67/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.6796 - mae: 1.6595 - val_loss: 3.8114 - val_mae: 1.4754\n",
            "Epoch 68/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.3523 - mae: 1.6080 - val_loss: 3.4645 - val_mae: 1.3883\n",
            "Epoch 69/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.9922 - mae: 1.5433 - val_loss: 3.2252 - val_mae: 1.3363\n",
            "Epoch 70/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.6423 - mae: 1.4711 - val_loss: 3.0528 - val_mae: 1.3053\n",
            "Epoch 71/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.5423 - mae: 1.4585 - val_loss: 3.0874 - val_mae: 1.3396\n",
            "Epoch 72/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2904 - mae: 1.4112 - val_loss: 2.6926 - val_mae: 1.1722\n",
            "Epoch 73/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2119 - mae: 1.3814 - val_loss: 2.6893 - val_mae: 1.2277\n",
            "Epoch 74/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9456 - mae: 1.3449 - val_loss: 2.5717 - val_mae: 1.1964\n",
            "Epoch 75/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8773 - mae: 1.3128 - val_loss: 2.8599 - val_mae: 1.2883\n",
            "Epoch 76/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2.6368 - mae: 1.2848 - val_loss: 2.3329 - val_mae: 1.1207\n",
            "Epoch 77/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2.5609 - mae: 1.2541 - val_loss: 2.3201 - val_mae: 1.1290\n",
            "Epoch 78/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.4311 - mae: 1.2292 - val_loss: 2.1871 - val_mae: 1.0842\n",
            "Epoch 79/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.3822 - mae: 1.2228 - val_loss: 2.3478 - val_mae: 1.1491\n",
            "Epoch 80/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.2475 - mae: 1.1879 - val_loss: 2.1346 - val_mae: 1.0802\n",
            "Epoch 81/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.1995 - mae: 1.1770 - val_loss: 2.0232 - val_mae: 1.0399\n",
            "Epoch 82/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.1236 - mae: 1.1627 - val_loss: 2.1201 - val_mae: 1.0902\n",
            "Epoch 83/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.0689 - mae: 1.1484 - val_loss: 1.9707 - val_mae: 1.0400\n",
            "Epoch 84/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.9990 - mae: 1.1204 - val_loss: 1.9992 - val_mae: 1.0647\n",
            "Epoch 85/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.9556 - mae: 1.1189 - val_loss: 1.9153 - val_mae: 1.0336\n",
            "Epoch 86/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.9426 - mae: 1.0938 - val_loss: 2.0211 - val_mae: 1.0760\n",
            "Epoch 87/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.8741 - mae: 1.0768 - val_loss: 1.8401 - val_mae: 1.0195\n",
            "Epoch 88/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7851 - mae: 1.0528 - val_loss: 1.8262 - val_mae: 1.0260\n",
            "Epoch 89/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7757 - mae: 1.0511 - val_loss: 1.7944 - val_mae: 1.0098\n",
            "Epoch 90/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7212 - mae: 1.0452 - val_loss: 1.8007 - val_mae: 1.0294\n",
            "Epoch 91/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.6504 - mae: 1.0149 - val_loss: 1.8117 - val_mae: 1.0215\n",
            "Epoch 92/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.6660 - mae: 1.0288 - val_loss: 1.9672 - val_mae: 1.0746\n",
            "Epoch 93/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.6241 - mae: 1.0149 - val_loss: 1.7618 - val_mae: 1.0210\n",
            "Epoch 94/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.6318 - mae: 0.9968 - val_loss: 1.8432 - val_mae: 1.0376\n",
            "Epoch 95/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.6041 - mae: 0.9996 - val_loss: 1.6879 - val_mae: 0.9979\n",
            "Epoch 96/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5656 - mae: 0.9962 - val_loss: 1.6657 - val_mae: 0.9823\n",
            "Epoch 97/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5144 - mae: 0.9754 - val_loss: 1.7090 - val_mae: 1.0256\n",
            "Epoch 98/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5197 - mae: 0.9739 - val_loss: 2.0384 - val_mae: 1.0959\n",
            "Epoch 99/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5193 - mae: 0.9732 - val_loss: 1.7176 - val_mae: 1.0355\n",
            "Epoch 100/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4824 - mae: 0.9658 - val_loss: 1.6736 - val_mae: 0.9754\n",
            "Epoch 101/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4272 - mae: 0.9546 - val_loss: 1.6314 - val_mae: 0.9629\n",
            "Epoch 102/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4713 - mae: 0.9625 - val_loss: 1.5808 - val_mae: 0.9795\n",
            "Epoch 103/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3948 - mae: 0.9356 - val_loss: 1.7286 - val_mae: 1.0547\n",
            "Epoch 104/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3954 - mae: 0.9436 - val_loss: 1.5460 - val_mae: 0.9430\n",
            "Epoch 105/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3662 - mae: 0.9284 - val_loss: 1.6851 - val_mae: 0.9814\n",
            "Epoch 106/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.3582 - mae: 0.9234 - val_loss: 1.4928 - val_mae: 0.9400\n",
            "Epoch 107/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3280 - mae: 0.9158 - val_loss: 1.6316 - val_mae: 0.9641\n",
            "Epoch 108/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3580 - mae: 0.9259 - val_loss: 1.7338 - val_mae: 0.9973\n",
            "Epoch 109/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3030 - mae: 0.9075 - val_loss: 1.6441 - val_mae: 0.9658\n",
            "Epoch 110/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3044 - mae: 0.9130 - val_loss: 1.4171 - val_mae: 0.9160\n",
            "Epoch 111/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2744 - mae: 0.8924 - val_loss: 1.6786 - val_mae: 0.9742\n",
            "Epoch 112/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2943 - mae: 0.9143 - val_loss: 1.4028 - val_mae: 0.9278\n",
            "Epoch 113/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2377 - mae: 0.8829 - val_loss: 1.4056 - val_mae: 0.9314\n",
            "Epoch 114/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2403 - mae: 0.8870 - val_loss: 1.4827 - val_mae: 0.9785\n",
            "Epoch 115/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2546 - mae: 0.8982 - val_loss: 1.5288 - val_mae: 0.9296\n",
            "Epoch 116/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2170 - mae: 0.8718 - val_loss: 1.4446 - val_mae: 0.9003\n",
            "Epoch 117/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2370 - mae: 0.8788 - val_loss: 1.6291 - val_mae: 0.9608\n",
            "Epoch 118/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2220 - mae: 0.8940 - val_loss: 1.3527 - val_mae: 0.9210\n",
            "Epoch 119/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1738 - mae: 0.8703 - val_loss: 1.3085 - val_mae: 0.8818\n",
            "Epoch 120/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1632 - mae: 0.8564 - val_loss: 1.5248 - val_mae: 0.9962\n",
            "Epoch 121/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2216 - mae: 0.8766 - val_loss: 1.3001 - val_mae: 0.8771\n",
            "Epoch 122/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1968 - mae: 0.8724 - val_loss: 1.4122 - val_mae: 0.8885\n",
            "Epoch 123/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2001 - mae: 0.8691 - val_loss: 1.3985 - val_mae: 0.8877\n",
            "Epoch 124/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1412 - mae: 0.8483 - val_loss: 1.3274 - val_mae: 0.8659\n",
            "Epoch 125/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1571 - mae: 0.8633 - val_loss: 1.3456 - val_mae: 0.9260\n",
            "Epoch 126/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1504 - mae: 0.8584 - val_loss: 1.2765 - val_mae: 0.8687\n",
            "Epoch 127/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1839 - mae: 0.8688 - val_loss: 1.2584 - val_mae: 0.8721\n",
            "Epoch 128/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1516 - mae: 0.8585 - val_loss: 1.3573 - val_mae: 0.9395\n",
            "Epoch 129/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1587 - mae: 0.8563 - val_loss: 1.2572 - val_mae: 0.8816\n",
            "Epoch 130/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1504 - mae: 0.8499 - val_loss: 1.2540 - val_mae: 0.8878\n",
            "Epoch 131/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1286 - mae: 0.8320 - val_loss: 1.2492 - val_mae: 0.8585\n",
            "Epoch 132/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1216 - mae: 0.8433 - val_loss: 1.2696 - val_mae: 0.8949\n",
            "Epoch 133/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1474 - mae: 0.8603 - val_loss: 1.2381 - val_mae: 0.8709\n",
            "Epoch 134/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1360 - mae: 0.8494 - val_loss: 1.2390 - val_mae: 0.8845\n",
            "Epoch 135/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1270 - mae: 0.8434 - val_loss: 1.2825 - val_mae: 0.9069\n",
            "Epoch 136/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1362 - mae: 0.8530 - val_loss: 1.2340 - val_mae: 0.8665\n",
            "Epoch 137/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0960 - mae: 0.8377 - val_loss: 1.2362 - val_mae: 0.8788\n",
            "Epoch 138/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1234 - mae: 0.8505 - val_loss: 1.4049 - val_mae: 0.9607\n",
            "Epoch 139/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1247 - mae: 0.8317 - val_loss: 1.4029 - val_mae: 0.9602\n",
            "Epoch 140/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1037 - mae: 0.8379 - val_loss: 1.2642 - val_mae: 0.8999\n",
            "Epoch 141/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1100 - mae: 0.8407 - val_loss: 1.2385 - val_mae: 0.8512\n",
            "Epoch 142/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1071 - mae: 0.8242 - val_loss: 1.5306 - val_mae: 1.0096\n",
            "Epoch 143/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1388 - mae: 0.8451 - val_loss: 1.2314 - val_mae: 0.8528\n",
            "Epoch 144/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0787 - mae: 0.8263 - val_loss: 1.2486 - val_mae: 0.8999\n",
            "Epoch 145/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1105 - mae: 0.8400 - val_loss: 1.2460 - val_mae: 0.8904\n",
            "Epoch 146/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1218 - mae: 0.8425 - val_loss: 1.2600 - val_mae: 0.8537\n",
            "Epoch 147/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0900 - mae: 0.8290 - val_loss: 1.3750 - val_mae: 0.8834\n",
            "Epoch 148/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1014 - mae: 0.8368 - val_loss: 1.2143 - val_mae: 0.8573\n",
            "Epoch 149/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1154 - mae: 0.8361 - val_loss: 1.2613 - val_mae: 0.8539\n",
            "Epoch 150/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1194 - mae: 0.8493 - val_loss: 1.2878 - val_mae: 0.9188\n",
            "Epoch 151/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1128 - mae: 0.8431 - val_loss: 1.2029 - val_mae: 0.8607\n",
            "Epoch 152/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1029 - mae: 0.8412 - val_loss: 1.2253 - val_mae: 0.8814\n",
            "Epoch 153/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0743 - mae: 0.8285 - val_loss: 1.2820 - val_mae: 0.8528\n",
            "Epoch 154/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0842 - mae: 0.8287 - val_loss: 1.2016 - val_mae: 0.8436\n",
            "Epoch 155/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0802 - mae: 0.8309 - val_loss: 1.1940 - val_mae: 0.8505\n",
            "Epoch 156/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0807 - mae: 0.8288 - val_loss: 1.2240 - val_mae: 0.8532\n",
            "Epoch 157/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0816 - mae: 0.8243 - val_loss: 1.2309 - val_mae: 0.8445\n",
            "Epoch 158/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0941 - mae: 0.8349 - val_loss: 1.3694 - val_mae: 0.9472\n",
            "Epoch 159/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0754 - mae: 0.8259 - val_loss: 1.3580 - val_mae: 0.9413\n",
            "Epoch 160/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0920 - mae: 0.8279 - val_loss: 1.2061 - val_mae: 0.8729\n",
            "Epoch 161/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0800 - mae: 0.8303 - val_loss: 1.1845 - val_mae: 0.8443\n",
            "Epoch 162/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0621 - mae: 0.8222 - val_loss: 1.1928 - val_mae: 0.8432\n",
            "Epoch 163/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0815 - mae: 0.8307 - val_loss: 1.1889 - val_mae: 0.8555\n",
            "Epoch 164/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0717 - mae: 0.8258 - val_loss: 1.2745 - val_mae: 0.9063\n",
            "Epoch 165/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0935 - mae: 0.8422 - val_loss: 1.2305 - val_mae: 0.8881\n",
            "Epoch 166/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0660 - mae: 0.8271 - val_loss: 1.2414 - val_mae: 0.8951\n",
            "Epoch 167/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0874 - mae: 0.8385 - val_loss: 1.3373 - val_mae: 0.8710\n",
            "Epoch 168/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0831 - mae: 0.8349 - val_loss: 1.2693 - val_mae: 0.9050\n",
            "Epoch 169/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0601 - mae: 0.8215 - val_loss: 1.4254 - val_mae: 0.9071\n",
            "Epoch 170/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0850 - mae: 0.8319 - val_loss: 1.5833 - val_mae: 1.0200\n",
            "Epoch 171/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0955 - mae: 0.8374 - val_loss: 1.2529 - val_mae: 0.8994\n",
            "Epoch 172/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0767 - mae: 0.8246 - val_loss: 1.1884 - val_mae: 0.8360\n",
            "Epoch 173/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0745 - mae: 0.8303 - val_loss: 1.2561 - val_mae: 0.8979\n",
            "Epoch 174/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0668 - mae: 0.8265 - val_loss: 1.2195 - val_mae: 0.8825\n",
            "Epoch 175/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0771 - mae: 0.8326 - val_loss: 1.2007 - val_mae: 0.8341\n",
            "Epoch 176/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0419 - mae: 0.8214 - val_loss: 1.4410 - val_mae: 0.9647\n",
            "Epoch 177/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1042 - mae: 0.8428 - val_loss: 1.1750 - val_mae: 0.8494\n",
            "Epoch 178/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0502 - mae: 0.8141 - val_loss: 1.3585 - val_mae: 0.9383\n",
            "Epoch 179/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0865 - mae: 0.8319 - val_loss: 1.2195 - val_mae: 0.8350\n",
            "Epoch 180/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0552 - mae: 0.8328 - val_loss: 1.2822 - val_mae: 0.8494\n",
            "Epoch 181/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0928 - mae: 0.8376 - val_loss: 1.2280 - val_mae: 0.8346\n",
            "Epoch 182/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0589 - mae: 0.8192 - val_loss: 1.1693 - val_mae: 0.8397\n",
            "Epoch 183/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0626 - mae: 0.8341 - val_loss: 1.1712 - val_mae: 0.8394\n",
            "Epoch 184/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0569 - mae: 0.8250 - val_loss: 1.2611 - val_mae: 0.9023\n",
            "Epoch 185/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1175 - mae: 0.8503 - val_loss: 1.1653 - val_mae: 0.8480\n",
            "Epoch 186/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0548 - mae: 0.8250 - val_loss: 1.1730 - val_mae: 0.8557\n",
            "Epoch 187/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0729 - mae: 0.8334 - val_loss: 1.3495 - val_mae: 0.9304\n",
            "Epoch 188/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0941 - mae: 0.8402 - val_loss: 1.2684 - val_mae: 0.8485\n",
            "Epoch 189/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0576 - mae: 0.8219 - val_loss: 1.1654 - val_mae: 0.8412\n",
            "Epoch 190/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0374 - mae: 0.8151 - val_loss: 1.2267 - val_mae: 0.8340\n",
            "Epoch 191/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0789 - mae: 0.8308 - val_loss: 1.1941 - val_mae: 0.8713\n",
            "Epoch 192/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0553 - mae: 0.8162 - val_loss: 1.2758 - val_mae: 0.9072\n",
            "Epoch 193/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0401 - mae: 0.8213 - val_loss: 1.3267 - val_mae: 0.8693\n",
            "Epoch 194/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0656 - mae: 0.8254 - val_loss: 1.3942 - val_mae: 0.8956\n",
            "Epoch 195/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0624 - mae: 0.8305 - val_loss: 1.2397 - val_mae: 0.8894\n",
            "Epoch 196/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0659 - mae: 0.8320 - val_loss: 1.1725 - val_mae: 0.8532\n",
            "Epoch 197/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0880 - mae: 0.8337 - val_loss: 1.2160 - val_mae: 0.8775\n",
            "Epoch 198/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0570 - mae: 0.8211 - val_loss: 1.1716 - val_mae: 0.8297\n",
            "Epoch 199/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0619 - mae: 0.8253 - val_loss: 1.1868 - val_mae: 0.8312\n",
            "Epoch 200/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0697 - mae: 0.8286 - val_loss: 1.3146 - val_mae: 0.8624\n",
            "Epoch 201/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0493 - mae: 0.8254 - val_loss: 1.1725 - val_mae: 0.8575\n",
            "Epoch 202/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0583 - mae: 0.8233 - val_loss: 1.2277 - val_mae: 0.8834\n",
            "Epoch 203/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0535 - mae: 0.8188 - val_loss: 1.2331 - val_mae: 0.8394\n",
            "Epoch 204/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0403 - mae: 0.8203 - val_loss: 1.2060 - val_mae: 0.8265\n",
            "Epoch 205/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0521 - mae: 0.8233 - val_loss: 1.1629 - val_mae: 0.8389\n",
            "Epoch 206/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0483 - mae: 0.8198 - val_loss: 1.2053 - val_mae: 0.8753\n",
            "Epoch 207/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0473 - mae: 0.8188 - val_loss: 1.1598 - val_mae: 0.8427\n",
            "Epoch 208/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0332 - mae: 0.8192 - val_loss: 1.4418 - val_mae: 0.9616\n",
            "Epoch 209/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0477 - mae: 0.8190 - val_loss: 1.1936 - val_mae: 0.8681\n",
            "Epoch 210/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0275 - mae: 0.8155 - val_loss: 1.3663 - val_mae: 0.9379\n",
            "Epoch 211/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0308 - mae: 0.8171 - val_loss: 1.4761 - val_mae: 0.9754\n",
            "Epoch 212/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0659 - mae: 0.8287 - val_loss: 1.1611 - val_mae: 0.8229\n",
            "Epoch 213/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0575 - mae: 0.8257 - val_loss: 1.2043 - val_mae: 0.8763\n",
            "Epoch 214/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0326 - mae: 0.8180 - val_loss: 1.2871 - val_mae: 0.9117\n",
            "Epoch 215/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0714 - mae: 0.8296 - val_loss: 1.2275 - val_mae: 0.8782\n",
            "Epoch 216/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0331 - mae: 0.8181 - val_loss: 1.3816 - val_mae: 0.8926\n",
            "Epoch 217/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0779 - mae: 0.8304 - val_loss: 1.2734 - val_mae: 0.9056\n",
            "Epoch 218/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0315 - mae: 0.8159 - val_loss: 1.1492 - val_mae: 0.8208\n",
            "Epoch 219/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0532 - mae: 0.8236 - val_loss: 1.1840 - val_mae: 0.8685\n",
            "Epoch 220/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0897 - mae: 0.8309 - val_loss: 1.1510 - val_mae: 0.8382\n",
            "Epoch 221/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0246 - mae: 0.8040 - val_loss: 1.3312 - val_mae: 0.8733\n",
            "Epoch 222/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0489 - mae: 0.8227 - val_loss: 1.1655 - val_mae: 0.8570\n",
            "Epoch 223/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0215 - mae: 0.8059 - val_loss: 1.3567 - val_mae: 0.9362\n",
            "Epoch 224/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0523 - mae: 0.8124 - val_loss: 1.1702 - val_mae: 0.8202\n",
            "Epoch 225/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0265 - mae: 0.8104 - val_loss: 1.2489 - val_mae: 0.8987\n",
            "Epoch 226/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0690 - mae: 0.8270 - val_loss: 1.2660 - val_mae: 0.8452\n",
            "Epoch 227/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0298 - mae: 0.8095 - val_loss: 1.2342 - val_mae: 0.8895\n",
            "Epoch 228/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0483 - mae: 0.8204 - val_loss: 1.2013 - val_mae: 0.8255\n",
            "Epoch 229/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0593 - mae: 0.8378 - val_loss: 1.1728 - val_mae: 0.8208\n",
            "Epoch 230/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0487 - mae: 0.8213 - val_loss: 1.2919 - val_mae: 0.9085\n",
            "Epoch 231/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0796 - mae: 0.8420 - val_loss: 1.1347 - val_mae: 0.8265\n",
            "Epoch 232/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0166 - mae: 0.8158 - val_loss: 1.1796 - val_mae: 0.8222\n",
            "Epoch 233/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0564 - mae: 0.8179 - val_loss: 1.1381 - val_mae: 0.8242\n",
            "Epoch 234/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0331 - mae: 0.8172 - val_loss: 1.1447 - val_mae: 0.8200\n",
            "Epoch 235/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0372 - mae: 0.8233 - val_loss: 1.1477 - val_mae: 0.8208\n",
            "Epoch 236/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0375 - mae: 0.8215 - val_loss: 1.5880 - val_mae: 0.9590\n",
            "Epoch 237/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0788 - mae: 0.8202 - val_loss: 1.1381 - val_mae: 0.8411\n",
            "Epoch 238/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0339 - mae: 0.8132 - val_loss: 1.2569 - val_mae: 0.8984\n",
            "Epoch 239/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0197 - mae: 0.8064 - val_loss: 1.2572 - val_mae: 0.9013\n",
            "Epoch 240/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0804 - mae: 0.8350 - val_loss: 1.1541 - val_mae: 0.8518\n",
            "Epoch 241/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0207 - mae: 0.8177 - val_loss: 1.1360 - val_mae: 0.8327\n",
            "Epoch 242/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0546 - mae: 0.8193 - val_loss: 1.2634 - val_mae: 0.9025\n",
            "Epoch 243/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0409 - mae: 0.8234 - val_loss: 1.4729 - val_mae: 0.9759\n",
            "Epoch 244/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0635 - mae: 0.8365 - val_loss: 1.1806 - val_mae: 0.8686\n",
            "Epoch 245/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0365 - mae: 0.8211 - val_loss: 1.1560 - val_mae: 0.8543\n",
            "Epoch 246/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0378 - mae: 0.8139 - val_loss: 1.1925 - val_mae: 0.8572\n",
            "Epoch 247/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0683 - mae: 0.8287 - val_loss: 1.2129 - val_mae: 0.8797\n",
            "Epoch 248/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0230 - mae: 0.8127 - val_loss: 1.1358 - val_mae: 0.8389\n",
            "Epoch 249/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0443 - mae: 0.8170 - val_loss: 1.1444 - val_mae: 0.8431\n",
            "Epoch 250/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0417 - mae: 0.8216 - val_loss: 1.1551 - val_mae: 0.8180\n",
            "Epoch 251/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0523 - mae: 0.8299 - val_loss: 1.2203 - val_mae: 0.8335\n",
            "Epoch 252/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0409 - mae: 0.8192 - val_loss: 1.1495 - val_mae: 0.8467\n",
            "Epoch 253/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0308 - mae: 0.8169 - val_loss: 1.2731 - val_mae: 0.9021\n",
            "Epoch 254/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0248 - mae: 0.8200 - val_loss: 1.2887 - val_mae: 0.9090\n",
            "Epoch 255/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0159 - mae: 0.8125 - val_loss: 1.2592 - val_mae: 0.8444\n",
            "Epoch 256/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0288 - mae: 0.8151 - val_loss: 1.1867 - val_mae: 0.8591\n",
            "Epoch 257/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0364 - mae: 0.8127 - val_loss: 1.2734 - val_mae: 0.8528\n",
            "Epoch 258/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0376 - mae: 0.8258 - val_loss: 1.1381 - val_mae: 0.8195\n",
            "Epoch 259/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0497 - mae: 0.8257 - val_loss: 1.2126 - val_mae: 0.8850\n",
            "Epoch 260/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0276 - mae: 0.8166 - val_loss: 1.1609 - val_mae: 0.8595\n",
            "Epoch 261/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0462 - mae: 0.8162 - val_loss: 1.1593 - val_mae: 0.8196\n",
            "Epoch 262/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0235 - mae: 0.8089 - val_loss: 1.1348 - val_mae: 0.8408\n",
            "Epoch 263/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0330 - mae: 0.8135 - val_loss: 1.3082 - val_mae: 0.9181\n",
            "Epoch 264/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0559 - mae: 0.8198 - val_loss: 1.5522 - val_mae: 1.0038\n",
            "Epoch 265/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0330 - mae: 0.8170 - val_loss: 1.2842 - val_mae: 0.8538\n",
            "Epoch 266/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0279 - mae: 0.8225 - val_loss: 1.1831 - val_mae: 0.8714\n",
            "Epoch 267/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0199 - mae: 0.8115 - val_loss: 1.2134 - val_mae: 0.8317\n",
            "Epoch 268/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0184 - mae: 0.8110 - val_loss: 1.1306 - val_mae: 0.8362\n",
            "Epoch 269/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0365 - mae: 0.8098 - val_loss: 1.1572 - val_mae: 0.8155\n",
            "Epoch 270/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0374 - mae: 0.8083 - val_loss: 1.1366 - val_mae: 0.8192\n",
            "Epoch 271/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0267 - mae: 0.8130 - val_loss: 1.1449 - val_mae: 0.8495\n",
            "Epoch 272/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0203 - mae: 0.8102 - val_loss: 1.1440 - val_mae: 0.8296\n",
            "Epoch 273/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0199 - mae: 0.8135 - val_loss: 1.1409 - val_mae: 0.8410\n",
            "Epoch 274/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0143 - mae: 0.8160 - val_loss: 1.2069 - val_mae: 0.8820\n",
            "Epoch 275/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0363 - mae: 0.8183 - val_loss: 1.1783 - val_mae: 0.8617\n",
            "Epoch 276/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0177 - mae: 0.8159 - val_loss: 1.2906 - val_mae: 0.9114\n",
            "Epoch 277/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0286 - mae: 0.8202 - val_loss: 1.1465 - val_mae: 0.8259\n",
            "Epoch 278/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0447 - mae: 0.8227 - val_loss: 1.1259 - val_mae: 0.8185\n",
            "Epoch 279/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0391 - mae: 0.8224 - val_loss: 1.1761 - val_mae: 0.8665\n",
            "Epoch 280/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0299 - mae: 0.8118 - val_loss: 1.1720 - val_mae: 0.8658\n",
            "Epoch 281/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0097 - mae: 0.8147 - val_loss: 1.1250 - val_mae: 0.8234\n",
            "Epoch 282/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0287 - mae: 0.8153 - val_loss: 1.1474 - val_mae: 0.8143\n",
            "Epoch 283/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0120 - mae: 0.8025 - val_loss: 1.1396 - val_mae: 0.8212\n",
            "Epoch 284/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0660 - mae: 0.8160 - val_loss: 1.1799 - val_mae: 0.8666\n",
            "Epoch 285/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0080 - mae: 0.8101 - val_loss: 1.1426 - val_mae: 0.8155\n",
            "Epoch 286/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0224 - mae: 0.8186 - val_loss: 1.1230 - val_mae: 0.8353\n",
            "Epoch 287/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0270 - mae: 0.8159 - val_loss: 1.3268 - val_mae: 0.9268\n",
            "Epoch 288/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9919 - mae: 0.7952 - val_loss: 1.3127 - val_mae: 0.9241\n",
            "Epoch 289/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0145 - mae: 0.8060 - val_loss: 1.2635 - val_mae: 0.9012\n",
            "Epoch 290/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0312 - mae: 0.8152 - val_loss: 1.1495 - val_mae: 0.8149\n",
            "Epoch 291/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0535 - mae: 0.8350 - val_loss: 1.1541 - val_mae: 0.8532\n",
            "Epoch 292/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9893 - mae: 0.7977 - val_loss: 1.1545 - val_mae: 0.8117\n",
            "Epoch 293/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0346 - mae: 0.8254 - val_loss: 1.1718 - val_mae: 0.8674\n",
            "Epoch 294/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0242 - mae: 0.8155 - val_loss: 1.2973 - val_mae: 0.9108\n",
            "Epoch 295/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0336 - mae: 0.8031 - val_loss: 1.2403 - val_mae: 0.8393\n",
            "Epoch 296/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0196 - mae: 0.8140 - val_loss: 1.2392 - val_mae: 0.8926\n",
            "Epoch 297/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0187 - mae: 0.8112 - val_loss: 1.2800 - val_mae: 0.9091\n",
            "Epoch 298/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0341 - mae: 0.8214 - val_loss: 1.1159 - val_mae: 0.8143\n",
            "Epoch 299/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0378 - mae: 0.8214 - val_loss: 1.1691 - val_mae: 0.8170\n",
            "Epoch 300/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0072 - mae: 0.8149 - val_loss: 1.1752 - val_mae: 0.8677\n",
            "Epoch 301/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9969 - mae: 0.8078 - val_loss: 1.1127 - val_mae: 0.8238\n",
            "Epoch 302/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0242 - mae: 0.8070 - val_loss: 1.2669 - val_mae: 0.8476\n",
            "Epoch 303/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0270 - mae: 0.8149 - val_loss: 1.1125 - val_mae: 0.8142\n",
            "Epoch 304/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0343 - mae: 0.8123 - val_loss: 1.1162 - val_mae: 0.8337\n",
            "Epoch 305/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0020 - mae: 0.8043 - val_loss: 1.1376 - val_mae: 0.8521\n",
            "Epoch 306/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0359 - mae: 0.8272 - val_loss: 1.1274 - val_mae: 0.8292\n",
            "Epoch 307/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0590 - mae: 0.8235 - val_loss: 1.1159 - val_mae: 0.8090\n",
            "Epoch 308/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0220 - mae: 0.8214 - val_loss: 1.4652 - val_mae: 0.9752\n",
            "Epoch 309/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0143 - mae: 0.8152 - val_loss: 1.1133 - val_mae: 0.8249\n",
            "Epoch 310/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9871 - mae: 0.7918 - val_loss: 1.1792 - val_mae: 0.8241\n",
            "Epoch 311/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0186 - mae: 0.8143 - val_loss: 1.1704 - val_mae: 0.8245\n",
            "Epoch 312/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0347 - mae: 0.8106 - val_loss: 1.1320 - val_mae: 0.8424\n",
            "Epoch 313/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9926 - mae: 0.8014 - val_loss: 1.1893 - val_mae: 0.8704\n",
            "Epoch 314/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0228 - mae: 0.8144 - val_loss: 1.1206 - val_mae: 0.8136\n",
            "Epoch 315/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0182 - mae: 0.8158 - val_loss: 1.1101 - val_mae: 0.8298\n",
            "Epoch 316/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0071 - mae: 0.8028 - val_loss: 1.1307 - val_mae: 0.8451\n",
            "Epoch 317/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0279 - mae: 0.8133 - val_loss: 1.4117 - val_mae: 0.9591\n",
            "Epoch 318/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0194 - mae: 0.8076 - val_loss: 1.1128 - val_mae: 0.8145\n",
            "Epoch 319/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0521 - mae: 0.8200 - val_loss: 1.1369 - val_mae: 0.8398\n",
            "Epoch 320/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0175 - mae: 0.8039 - val_loss: 1.3012 - val_mae: 0.9163\n",
            "Epoch 321/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0066 - mae: 0.7989 - val_loss: 1.4362 - val_mae: 0.9674\n",
            "Epoch 322/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0448 - mae: 0.8133 - val_loss: 1.1251 - val_mae: 0.8131\n",
            "Epoch 323/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0227 - mae: 0.8095 - val_loss: 1.3992 - val_mae: 0.9541\n",
            "Epoch 324/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0081 - mae: 0.8101 - val_loss: 1.2156 - val_mae: 0.8865\n",
            "Epoch 325/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0019 - mae: 0.7997 - val_loss: 1.1125 - val_mae: 0.8323\n",
            "Epoch 326/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0454 - mae: 0.8181 - val_loss: 1.3712 - val_mae: 0.9434\n",
            "Epoch 327/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0215 - mae: 0.8113 - val_loss: 1.1150 - val_mae: 0.8362\n",
            "Epoch 328/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0401 - mae: 0.8098 - val_loss: 1.1046 - val_mae: 0.8231\n",
            "Epoch 329/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9814 - mae: 0.7904 - val_loss: 1.3141 - val_mae: 0.9259\n",
            "Epoch 330/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0342 - mae: 0.8165 - val_loss: 1.1159 - val_mae: 0.8159\n",
            "Epoch 331/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0120 - mae: 0.7968 - val_loss: 1.3728 - val_mae: 0.8906\n",
            "Epoch 332/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0065 - mae: 0.8126 - val_loss: 1.1690 - val_mae: 0.8247\n",
            "Epoch 333/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0340 - mae: 0.8118 - val_loss: 1.3780 - val_mae: 0.9466\n",
            "Epoch 334/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0002 - mae: 0.8052 - val_loss: 1.3161 - val_mae: 0.9263\n",
            "Epoch 335/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9991 - mae: 0.8011 - val_loss: 1.1332 - val_mae: 0.8459\n",
            "Epoch 336/1000\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 1.0636 - mae: 0.8186 - val_loss: 1.2404 - val_mae: 0.8922\n",
            "Epoch 337/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9619 - mae: 0.7863 - val_loss: 1.2340 - val_mae: 0.8928\n",
            "Epoch 338/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0258 - mae: 0.8081 - val_loss: 1.1781 - val_mae: 0.8657\n",
            "Epoch 339/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0272 - mae: 0.8147 - val_loss: 1.2900 - val_mae: 0.9159\n",
            "Epoch 340/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9902 - mae: 0.7939 - val_loss: 1.1655 - val_mae: 0.8586\n",
            "Epoch 341/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0231 - mae: 0.8005 - val_loss: 1.1432 - val_mae: 0.8175\n",
            "Epoch 342/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0241 - mae: 0.8105 - val_loss: 1.1150 - val_mae: 0.8312\n",
            "Epoch 343/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0143 - mae: 0.8033 - val_loss: 1.1565 - val_mae: 0.8191\n",
            "Epoch 344/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9927 - mae: 0.8089 - val_loss: 1.4238 - val_mae: 0.9596\n",
            "Epoch 345/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0210 - mae: 0.8057 - val_loss: 1.3586 - val_mae: 0.9416\n",
            "Epoch 346/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0148 - mae: 0.8082 - val_loss: 1.1710 - val_mae: 0.8691\n",
            "Epoch 347/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0141 - mae: 0.8169 - val_loss: 1.1349 - val_mae: 0.8481\n",
            "Epoch 348/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0320 - mae: 0.8061 - val_loss: 1.4303 - val_mae: 0.9667\n",
            "Epoch 349/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0004 - mae: 0.8010 - val_loss: 1.1183 - val_mae: 0.8280\n",
            "Epoch 350/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9955 - mae: 0.8049 - val_loss: 1.1995 - val_mae: 0.8770\n",
            "Epoch 351/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9813 - mae: 0.7952 - val_loss: 1.2303 - val_mae: 0.8929\n",
            "Epoch 352/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9955 - mae: 0.7923 - val_loss: 1.4810 - val_mae: 0.9258\n",
            "Epoch 353/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0193 - mae: 0.8087 - val_loss: 1.1385 - val_mae: 0.8485\n",
            "Epoch 354/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9962 - mae: 0.8050 - val_loss: 1.1168 - val_mae: 0.8156\n",
            "Epoch 355/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0280 - mae: 0.8071 - val_loss: 1.1210 - val_mae: 0.8132\n",
            "Epoch 356/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0270 - mae: 0.8098 - val_loss: 1.1362 - val_mae: 0.8468\n",
            "Epoch 357/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0049 - mae: 0.8037 - val_loss: 1.2254 - val_mae: 0.8915\n",
            "Epoch 358/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0109 - mae: 0.8108 - val_loss: 1.1471 - val_mae: 0.8557\n",
            "Epoch 359/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9850 - mae: 0.7956 - val_loss: 1.2636 - val_mae: 0.9045\n",
            "Epoch 360/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0080 - mae: 0.8043 - val_loss: 1.4063 - val_mae: 0.9594\n",
            "Epoch 361/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0051 - mae: 0.8011 - val_loss: 1.1883 - val_mae: 0.8289\n",
            "Epoch 362/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9998 - mae: 0.7979 - val_loss: 1.1646 - val_mae: 0.8667\n",
            "Epoch 363/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0067 - mae: 0.8126 - val_loss: 1.1653 - val_mae: 0.8673\n",
            "Epoch 364/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0272 - mae: 0.8176 - val_loss: 1.2152 - val_mae: 0.8849\n",
            "Epoch 365/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0094 - mae: 0.8131 - val_loss: 1.1115 - val_mae: 0.8188\n",
            "Epoch 366/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9653 - mae: 0.7871 - val_loss: 1.3493 - val_mae: 0.9385\n",
            "Epoch 367/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0092 - mae: 0.8130 - val_loss: 1.3246 - val_mae: 0.9308\n",
            "Epoch 368/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0145 - mae: 0.7936 - val_loss: 1.1484 - val_mae: 0.8604\n",
            "Epoch 369/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0067 - mae: 0.8056 - val_loss: 1.3259 - val_mae: 0.8731\n",
            "Epoch 370/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0208 - mae: 0.8138 - val_loss: 1.1109 - val_mae: 0.8181\n",
            "Epoch 371/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0121 - mae: 0.8115 - val_loss: 1.1161 - val_mae: 0.8208\n",
            "Epoch 372/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0141 - mae: 0.8076 - val_loss: 1.1292 - val_mae: 0.8154\n",
            "Epoch 373/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9893 - mae: 0.7937 - val_loss: 1.2295 - val_mae: 0.8942\n",
            "Epoch 374/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9995 - mae: 0.8020 - val_loss: 1.2416 - val_mae: 0.8516\n",
            "Epoch 375/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0172 - mae: 0.8079 - val_loss: 1.2569 - val_mae: 0.9029\n",
            "Epoch 376/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9800 - mae: 0.7989 - val_loss: 1.1365 - val_mae: 0.8465\n",
            "Epoch 377/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0022 - mae: 0.8011 - val_loss: 1.1333 - val_mae: 0.8298\n",
            "Epoch 378/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0147 - mae: 0.8087 - val_loss: 1.1265 - val_mae: 0.8391\n",
            "Epoch 379/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9746 - mae: 0.7945 - val_loss: 1.1324 - val_mae: 0.8454\n",
            "Epoch 380/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0147 - mae: 0.8056 - val_loss: 1.1215 - val_mae: 0.8295\n",
            "Epoch 381/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0125 - mae: 0.8070 - val_loss: 1.1201 - val_mae: 0.8386\n",
            "Epoch 382/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0067 - mae: 0.8026 - val_loss: 1.1286 - val_mae: 0.8360\n",
            "Epoch 383/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9845 - mae: 0.7926 - val_loss: 1.1396 - val_mae: 0.8470\n",
            "Epoch 384/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0337 - mae: 0.8169 - val_loss: 1.1287 - val_mae: 0.8455\n",
            "Epoch 385/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9812 - mae: 0.8021 - val_loss: 1.1398 - val_mae: 0.8128\n",
            "Epoch 386/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9965 - mae: 0.7906 - val_loss: 1.1127 - val_mae: 0.8249\n",
            "Epoch 387/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0026 - mae: 0.8109 - val_loss: 1.1349 - val_mae: 0.8470\n",
            "Epoch 388/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0155 - mae: 0.8093 - val_loss: 1.1554 - val_mae: 0.8596\n",
            "Epoch 389/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9926 - mae: 0.7927 - val_loss: 1.1587 - val_mae: 0.8575\n",
            "Epoch 390/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0085 - mae: 0.8016 - val_loss: 1.1180 - val_mae: 0.8266\n",
            "Epoch 391/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9910 - mae: 0.7994 - val_loss: 1.1232 - val_mae: 0.8252\n",
            "Epoch 392/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0109 - mae: 0.8060 - val_loss: 1.1851 - val_mae: 0.8724\n",
            "Epoch 393/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0031 - mae: 0.8091 - val_loss: 1.1265 - val_mae: 0.8190\n",
            "Epoch 394/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0048 - mae: 0.8049 - val_loss: 1.1210 - val_mae: 0.8323\n",
            "Epoch 395/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0008 - mae: 0.8036 - val_loss: 1.1531 - val_mae: 0.8128\n",
            "Epoch 396/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0253 - mae: 0.8011 - val_loss: 1.1211 - val_mae: 0.8285\n",
            "Epoch 397/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0028 - mae: 0.8077 - val_loss: 1.1858 - val_mae: 0.8682\n",
            "Epoch 398/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0101 - mae: 0.8134 - val_loss: 1.5740 - val_mae: 0.9635\n",
            "Epoch 399/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0006 - mae: 0.8006 - val_loss: 1.5392 - val_mae: 0.9509\n",
            "Epoch 400/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0028 - mae: 0.8108 - val_loss: 1.1059 - val_mae: 0.8227\n",
            "Epoch 401/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0174 - mae: 0.8098 - val_loss: 1.1091 - val_mae: 0.8319\n",
            "Epoch 402/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9962 - mae: 0.8012 - val_loss: 1.1091 - val_mae: 0.8186\n",
            "Epoch 403/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9768 - mae: 0.7975 - val_loss: 1.2788 - val_mae: 0.9149\n",
            "Epoch 404/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0110 - mae: 0.8121 - val_loss: 1.1462 - val_mae: 0.8525\n",
            "Epoch 405/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0055 - mae: 0.8107 - val_loss: 1.1077 - val_mae: 0.8130\n",
            "Epoch 406/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0118 - mae: 0.7991 - val_loss: 1.1143 - val_mae: 0.8196\n",
            "Epoch 407/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0432 - mae: 0.8189 - val_loss: 1.4246 - val_mae: 0.9657\n",
            "Epoch 408/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9953 - mae: 0.7992 - val_loss: 1.1099 - val_mae: 0.8105\n",
            "Epoch 409/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9949 - mae: 0.7978 - val_loss: 1.1977 - val_mae: 0.8770\n",
            "Epoch 410/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0074 - mae: 0.7995 - val_loss: 1.0996 - val_mae: 0.8192\n",
            "Epoch 411/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9984 - mae: 0.8026 - val_loss: 1.1059 - val_mae: 0.8249\n",
            "Epoch 412/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9965 - mae: 0.7999 - val_loss: 1.1385 - val_mae: 0.8350\n",
            "Epoch 413/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0034 - mae: 0.8038 - val_loss: 1.2215 - val_mae: 0.8430\n",
            "Epoch 414/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9927 - mae: 0.8011 - val_loss: 1.1738 - val_mae: 0.8671\n",
            "Epoch 415/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9569 - mae: 0.7674 - val_loss: 1.2249 - val_mae: 0.8929\n",
            "Epoch 416/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0137 - mae: 0.8117 - val_loss: 1.1022 - val_mae: 0.8096\n",
            "Epoch 417/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9948 - mae: 0.8024 - val_loss: 1.1185 - val_mae: 0.8255\n",
            "Epoch 418/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0125 - mae: 0.8024 - val_loss: 1.3694 - val_mae: 0.9451\n",
            "Epoch 419/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0244 - mae: 0.8060 - val_loss: 1.1050 - val_mae: 0.8097\n",
            "Epoch 420/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0039 - mae: 0.8000 - val_loss: 1.2745 - val_mae: 0.8548\n",
            "Epoch 421/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9789 - mae: 0.7989 - val_loss: 1.2853 - val_mae: 0.9162\n",
            "Epoch 422/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0241 - mae: 0.8012 - val_loss: 1.1226 - val_mae: 0.8191\n",
            "Epoch 423/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9876 - mae: 0.7978 - val_loss: 1.2218 - val_mae: 0.8427\n",
            "Epoch 424/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0042 - mae: 0.8082 - val_loss: 1.3782 - val_mae: 0.9491\n",
            "Epoch 425/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0078 - mae: 0.7989 - val_loss: 1.1256 - val_mae: 0.8216\n",
            "Epoch 426/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9804 - mae: 0.7984 - val_loss: 1.1566 - val_mae: 0.8558\n",
            "Epoch 427/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9860 - mae: 0.8017 - val_loss: 1.6434 - val_mae: 1.0337\n",
            "Epoch 428/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0116 - mae: 0.8086 - val_loss: 1.1757 - val_mae: 0.8242\n",
            "Epoch 429/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9910 - mae: 0.7960 - val_loss: 1.2016 - val_mae: 0.8316\n",
            "Epoch 430/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0189 - mae: 0.8069 - val_loss: 1.1111 - val_mae: 0.8268\n",
            "Epoch 431/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9993 - mae: 0.7962 - val_loss: 1.1025 - val_mae: 0.8198\n",
            "Epoch 432/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0044 - mae: 0.8062 - val_loss: 1.1061 - val_mae: 0.8307\n",
            "Epoch 433/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0031 - mae: 0.8067 - val_loss: 1.1423 - val_mae: 0.8121\n",
            "Epoch 434/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9994 - mae: 0.7978 - val_loss: 1.1361 - val_mae: 0.8103\n",
            "Epoch 435/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0046 - mae: 0.7997 - val_loss: 1.1168 - val_mae: 0.8089\n",
            "Epoch 436/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0048 - mae: 0.8085 - val_loss: 1.1086 - val_mae: 0.8203\n",
            "Epoch 437/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9811 - mae: 0.7963 - val_loss: 1.1240 - val_mae: 0.8388\n",
            "Epoch 438/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9920 - mae: 0.7953 - val_loss: 1.1110 - val_mae: 0.8283\n",
            "Epoch 439/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9932 - mae: 0.7986 - val_loss: 1.4183 - val_mae: 0.9138\n",
            "Epoch 440/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9784 - mae: 0.7989 - val_loss: 1.4446 - val_mae: 0.9709\n",
            "Epoch 441/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9742 - mae: 0.8024 - val_loss: 1.3096 - val_mae: 0.9243\n",
            "Epoch 442/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9994 - mae: 0.7993 - val_loss: 1.1546 - val_mae: 0.8338\n",
            "Epoch 443/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9997 - mae: 0.7975 - val_loss: 1.2611 - val_mae: 0.8543\n",
            "Epoch 444/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9728 - mae: 0.7917 - val_loss: 1.3314 - val_mae: 0.8814\n",
            "Epoch 445/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9815 - mae: 0.7958 - val_loss: 1.1010 - val_mae: 0.8287\n",
            "Epoch 446/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9921 - mae: 0.8009 - val_loss: 1.5697 - val_mae: 0.9611\n",
            "Epoch 447/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0079 - mae: 0.8113 - val_loss: 1.1483 - val_mae: 0.8503\n",
            "Epoch 448/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0038 - mae: 0.8001 - val_loss: 1.1220 - val_mae: 0.8309\n",
            "Epoch 449/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0081 - mae: 0.8021 - val_loss: 1.2498 - val_mae: 0.8996\n",
            "Epoch 450/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0084 - mae: 0.8078 - val_loss: 1.1245 - val_mae: 0.8405\n",
            "Epoch 451/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9843 - mae: 0.7927 - val_loss: 1.1625 - val_mae: 0.8222\n",
            "Epoch 452/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9962 - mae: 0.8016 - val_loss: 1.2061 - val_mae: 0.8348\n",
            "Epoch 453/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0321 - mae: 0.8110 - val_loss: 1.1737 - val_mae: 0.8627\n",
            "Epoch 454/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0117 - mae: 0.8133 - val_loss: 1.1560 - val_mae: 0.8535\n",
            "Epoch 455/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9925 - mae: 0.7901 - val_loss: 1.3345 - val_mae: 0.9333\n",
            "Epoch 456/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0165 - mae: 0.8019 - val_loss: 1.1199 - val_mae: 0.8224\n",
            "Epoch 457/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0069 - mae: 0.7990 - val_loss: 1.1134 - val_mae: 0.8265\n",
            "Epoch 458/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0102 - mae: 0.8049 - val_loss: 1.1095 - val_mae: 0.8313\n",
            "Epoch 459/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0147 - mae: 0.8010 - val_loss: 1.1165 - val_mae: 0.8259\n",
            "Epoch 460/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0014 - mae: 0.8066 - val_loss: 1.1313 - val_mae: 0.8071\n",
            "Epoch 461/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0186 - mae: 0.8055 - val_loss: 1.1447 - val_mae: 0.8509\n",
            "Epoch 462/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0067 - mae: 0.8002 - val_loss: 1.2987 - val_mae: 0.8707\n",
            "Epoch 463/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9962 - mae: 0.8019 - val_loss: 1.1200 - val_mae: 0.8126\n",
            "Epoch 464/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9869 - mae: 0.8045 - val_loss: 1.5304 - val_mae: 1.0045\n",
            "Epoch 465/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0235 - mae: 0.8090 - val_loss: 1.3592 - val_mae: 0.9414\n",
            "Epoch 466/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9863 - mae: 0.7924 - val_loss: 1.1796 - val_mae: 0.8658\n",
            "Epoch 467/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9953 - mae: 0.7984 - val_loss: 1.2210 - val_mae: 0.8898\n",
            "Epoch 468/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9844 - mae: 0.7998 - val_loss: 1.1883 - val_mae: 0.8695\n",
            "Epoch 469/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9921 - mae: 0.7976 - val_loss: 1.1048 - val_mae: 0.8119\n",
            "Epoch 470/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9969 - mae: 0.8046 - val_loss: 1.1111 - val_mae: 0.8293\n",
            "Epoch 471/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0180 - mae: 0.7973 - val_loss: 1.1186 - val_mae: 0.8078\n",
            "Epoch 472/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9827 - mae: 0.7944 - val_loss: 1.3904 - val_mae: 0.9544\n",
            "Epoch 473/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0007 - mae: 0.8031 - val_loss: 1.1568 - val_mae: 0.8591\n",
            "Epoch 474/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9845 - mae: 0.7901 - val_loss: 1.1246 - val_mae: 0.8402\n",
            "Epoch 475/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9934 - mae: 0.8032 - val_loss: 1.3420 - val_mae: 0.9360\n",
            "Epoch 476/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9899 - mae: 0.8029 - val_loss: 1.1033 - val_mae: 0.8222\n",
            "Epoch 477/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9991 - mae: 0.8045 - val_loss: 1.1074 - val_mae: 0.8175\n",
            "Epoch 478/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0125 - mae: 0.8039 - val_loss: 1.2832 - val_mae: 0.9160\n",
            "Epoch 479/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9930 - mae: 0.8018 - val_loss: 1.5373 - val_mae: 1.0033\n",
            "Epoch 480/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9925 - mae: 0.8045 - val_loss: 1.2438 - val_mae: 0.8977\n",
            "Epoch 481/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0048 - mae: 0.8006 - val_loss: 1.3285 - val_mae: 0.8790\n",
            "Epoch 482/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9966 - mae: 0.8017 - val_loss: 1.1087 - val_mae: 0.8125\n",
            "Epoch 483/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9694 - mae: 0.7862 - val_loss: 1.1229 - val_mae: 0.8390\n",
            "Epoch 484/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0090 - mae: 0.8055 - val_loss: 1.1089 - val_mae: 0.8133\n",
            "Epoch 485/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9858 - mae: 0.7990 - val_loss: 1.2524 - val_mae: 0.9040\n",
            "Epoch 486/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0106 - mae: 0.8059 - val_loss: 1.1757 - val_mae: 0.8662\n",
            "Epoch 487/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0013 - mae: 0.7988 - val_loss: 1.1946 - val_mae: 0.8330\n",
            "Epoch 488/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9964 - mae: 0.7983 - val_loss: 1.2563 - val_mae: 0.8993\n",
            "Epoch 489/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9857 - mae: 0.7935 - val_loss: 1.2393 - val_mae: 0.8921\n",
            "Epoch 490/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0036 - mae: 0.7989 - val_loss: 1.1461 - val_mae: 0.8533\n",
            "Epoch 491/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0011 - mae: 0.8027 - val_loss: 1.2017 - val_mae: 0.8792\n",
            "Epoch 492/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9851 - mae: 0.7966 - val_loss: 1.2786 - val_mae: 0.8575\n",
            "Epoch 493/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9797 - mae: 0.7949 - val_loss: 1.1037 - val_mae: 0.8109\n",
            "Epoch 494/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0084 - mae: 0.7968 - val_loss: 1.1542 - val_mae: 0.8541\n",
            "Epoch 495/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9550 - mae: 0.7923 - val_loss: 1.1137 - val_mae: 0.8314\n",
            "Epoch 496/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9974 - mae: 0.7934 - val_loss: 1.1272 - val_mae: 0.8281\n",
            "Epoch 497/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0051 - mae: 0.8095 - val_loss: 1.1565 - val_mae: 0.8552\n",
            "Epoch 498/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0077 - mae: 0.8000 - val_loss: 1.6324 - val_mae: 1.0433\n",
            "Epoch 499/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0011 - mae: 0.8063 - val_loss: 1.1032 - val_mae: 0.8217\n",
            "Epoch 500/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0115 - mae: 0.8058 - val_loss: 1.2162 - val_mae: 0.8904\n",
            "Epoch 501/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9895 - mae: 0.7999 - val_loss: 1.1332 - val_mae: 0.8474\n",
            "Epoch 502/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9811 - mae: 0.7965 - val_loss: 1.1799 - val_mae: 0.8670\n",
            "Epoch 503/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9985 - mae: 0.7962 - val_loss: 1.1154 - val_mae: 0.8145\n",
            "Epoch 504/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9988 - mae: 0.7979 - val_loss: 1.1927 - val_mae: 0.8760\n",
            "Epoch 505/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9614 - mae: 0.7899 - val_loss: 1.3802 - val_mae: 0.9519\n",
            "Epoch 506/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9818 - mae: 0.7941 - val_loss: 1.1166 - val_mae: 0.8272\n",
            "Epoch 507/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9833 - mae: 0.7930 - val_loss: 1.1588 - val_mae: 0.8641\n",
            "Epoch 508/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9779 - mae: 0.7957 - val_loss: 1.1629 - val_mae: 0.8638\n",
            "Epoch 509/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9738 - mae: 0.7994 - val_loss: 1.1924 - val_mae: 0.8773\n",
            "Epoch 510/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9789 - mae: 0.7932 - val_loss: 1.2099 - val_mae: 0.8866\n",
            "Epoch 511/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0070 - mae: 0.8079 - val_loss: 1.1118 - val_mae: 0.8252\n",
            "Epoch 512/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9540 - mae: 0.7788 - val_loss: 1.1310 - val_mae: 0.8134\n",
            "Epoch 513/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9892 - mae: 0.7956 - val_loss: 1.1084 - val_mae: 0.8264\n",
            "Epoch 514/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9753 - mae: 0.7896 - val_loss: 1.1875 - val_mae: 0.8755\n",
            "Epoch 515/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9928 - mae: 0.7986 - val_loss: 1.2718 - val_mae: 0.9108\n",
            "Epoch 516/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9576 - mae: 0.7830 - val_loss: 1.1170 - val_mae: 0.8329\n",
            "Epoch 517/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0017 - mae: 0.8021 - val_loss: 1.2125 - val_mae: 0.8392\n",
            "Epoch 518/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0295 - mae: 0.8112 - val_loss: 1.3606 - val_mae: 0.9445\n",
            "Epoch 519/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0142 - mae: 0.8057 - val_loss: 1.1153 - val_mae: 0.8304\n",
            "Epoch 520/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9886 - mae: 0.8013 - val_loss: 1.2206 - val_mae: 0.8875\n",
            "Epoch 521/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9946 - mae: 0.8057 - val_loss: 1.2136 - val_mae: 0.8867\n",
            "Epoch 522/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9861 - mae: 0.7963 - val_loss: 1.1510 - val_mae: 0.8551\n",
            "Epoch 523/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0068 - mae: 0.8076 - val_loss: 1.1088 - val_mae: 0.8293\n",
            "Epoch 524/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9896 - mae: 0.7961 - val_loss: 1.4901 - val_mae: 0.9369\n",
            "Epoch 525/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9892 - mae: 0.7966 - val_loss: 1.1388 - val_mae: 0.8547\n",
            "Epoch 526/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9970 - mae: 0.8007 - val_loss: 1.1291 - val_mae: 0.8106\n",
            "Epoch 527/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9924 - mae: 0.7993 - val_loss: 1.1261 - val_mae: 0.8362\n",
            "Epoch 528/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9608 - mae: 0.7824 - val_loss: 1.1420 - val_mae: 0.8495\n",
            "Epoch 529/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0193 - mae: 0.8068 - val_loss: 1.1899 - val_mae: 0.8740\n",
            "Epoch 530/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0146 - mae: 0.8051 - val_loss: 1.1922 - val_mae: 0.8769\n",
            "Epoch 531/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9834 - mae: 0.7966 - val_loss: 1.1372 - val_mae: 0.8523\n",
            "Epoch 532/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0041 - mae: 0.8010 - val_loss: 1.1221 - val_mae: 0.8163\n",
            "Epoch 533/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9730 - mae: 0.7885 - val_loss: 1.1048 - val_mae: 0.8172\n",
            "Epoch 534/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9942 - mae: 0.7913 - val_loss: 1.1603 - val_mae: 0.8298\n",
            "Epoch 535/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0098 - mae: 0.8031 - val_loss: 1.1259 - val_mae: 0.8129\n",
            "Epoch 536/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9895 - mae: 0.7978 - val_loss: 1.1914 - val_mae: 0.8730\n",
            "Epoch 537/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9776 - mae: 0.7924 - val_loss: 1.1093 - val_mae: 0.8288\n",
            "Epoch 538/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0226 - mae: 0.8101 - val_loss: 1.1212 - val_mae: 0.8193\n",
            "Epoch 539/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0114 - mae: 0.7934 - val_loss: 1.2358 - val_mae: 0.8426\n",
            "Epoch 540/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0166 - mae: 0.8044 - val_loss: 1.3774 - val_mae: 0.8913\n",
            "Epoch 541/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9756 - mae: 0.8004 - val_loss: 1.1109 - val_mae: 0.8215\n",
            "Epoch 542/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9979 - mae: 0.8024 - val_loss: 1.1134 - val_mae: 0.8111\n",
            "Epoch 543/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0044 - mae: 0.8041 - val_loss: 1.3112 - val_mae: 0.8718\n",
            "Epoch 544/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0012 - mae: 0.7991 - val_loss: 1.1072 - val_mae: 0.8170\n",
            "Epoch 545/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9891 - mae: 0.7954 - val_loss: 1.1741 - val_mae: 0.8722\n",
            "Epoch 546/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9810 - mae: 0.8024 - val_loss: 1.1092 - val_mae: 0.8098\n",
            "Epoch 547/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0046 - mae: 0.7910 - val_loss: 1.2460 - val_mae: 0.8511\n",
            "Epoch 548/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9551 - mae: 0.7907 - val_loss: 1.5197 - val_mae: 0.9969\n",
            "Epoch 549/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9936 - mae: 0.7992 - val_loss: 1.1254 - val_mae: 0.8153\n",
            "Epoch 550/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0229 - mae: 0.8078 - val_loss: 1.1255 - val_mae: 0.8396\n",
            "Epoch 551/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0248 - mae: 0.8177 - val_loss: 1.1924 - val_mae: 0.8326\n",
            "Epoch 552/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9991 - mae: 0.8008 - val_loss: 1.1153 - val_mae: 0.8059\n",
            "Epoch 553/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9958 - mae: 0.7975 - val_loss: 1.1333 - val_mae: 0.8439\n",
            "Epoch 554/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0048 - mae: 0.8159 - val_loss: 1.2646 - val_mae: 0.9099\n",
            "Epoch 555/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9717 - mae: 0.7834 - val_loss: 1.4283 - val_mae: 0.9153\n",
            "Epoch 556/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0030 - mae: 0.8053 - val_loss: 1.1902 - val_mae: 0.8302\n",
            "Epoch 557/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9848 - mae: 0.7983 - val_loss: 1.1322 - val_mae: 0.8158\n",
            "Epoch 558/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9910 - mae: 0.7935 - val_loss: 1.1076 - val_mae: 0.8159\n",
            "Epoch 559/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9976 - mae: 0.7976 - val_loss: 1.2222 - val_mae: 0.8860\n",
            "Epoch 560/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9793 - mae: 0.7990 - val_loss: 1.2061 - val_mae: 0.8314\n",
            "Epoch 561/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0073 - mae: 0.8127 - val_loss: 1.2573 - val_mae: 0.9041\n",
            "Epoch 562/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9831 - mae: 0.8019 - val_loss: 1.1838 - val_mae: 0.8689\n",
            "Epoch 563/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9997 - mae: 0.7935 - val_loss: 1.4270 - val_mae: 0.9681\n",
            "Epoch 564/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0116 - mae: 0.8028 - val_loss: 1.2513 - val_mae: 0.9054\n",
            "Epoch 565/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9966 - mae: 0.8114 - val_loss: 1.1336 - val_mae: 0.8475\n",
            "Epoch 566/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0099 - mae: 0.8119 - val_loss: 1.1060 - val_mae: 0.8218\n",
            "Epoch 567/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9838 - mae: 0.7866 - val_loss: 1.1105 - val_mae: 0.8176\n",
            "Epoch 568/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9935 - mae: 0.7941 - val_loss: 1.2601 - val_mae: 0.9081\n",
            "Epoch 569/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9967 - mae: 0.7993 - val_loss: 1.1099 - val_mae: 0.8170\n",
            "Epoch 570/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9810 - mae: 0.7946 - val_loss: 1.1874 - val_mae: 0.8745\n",
            "Epoch 571/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9890 - mae: 0.7886 - val_loss: 1.1248 - val_mae: 0.8302\n",
            "Epoch 572/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9663 - mae: 0.7931 - val_loss: 1.1285 - val_mae: 0.8107\n",
            "Epoch 573/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9851 - mae: 0.7885 - val_loss: 1.1089 - val_mae: 0.8211\n",
            "Epoch 574/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9820 - mae: 0.7956 - val_loss: 1.1686 - val_mae: 0.8651\n",
            "Epoch 575/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9928 - mae: 0.8050 - val_loss: 1.1135 - val_mae: 0.8184\n",
            "Epoch 576/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9679 - mae: 0.7951 - val_loss: 1.1789 - val_mae: 0.8740\n",
            "Epoch 577/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0105 - mae: 0.8010 - val_loss: 1.2988 - val_mae: 0.8642\n",
            "Epoch 578/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0115 - mae: 0.8073 - val_loss: 1.1394 - val_mae: 0.8497\n",
            "Epoch 579/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9792 - mae: 0.7911 - val_loss: 1.1808 - val_mae: 0.8257\n",
            "Epoch 580/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9836 - mae: 0.7927 - val_loss: 1.1124 - val_mae: 0.8337\n",
            "Epoch 581/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9993 - mae: 0.8020 - val_loss: 1.1176 - val_mae: 0.8086\n",
            "Epoch 582/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0086 - mae: 0.8142 - val_loss: 1.1153 - val_mae: 0.8286\n",
            "Epoch 583/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0017 - mae: 0.8032 - val_loss: 1.3830 - val_mae: 0.9533\n",
            "Epoch 584/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0031 - mae: 0.8061 - val_loss: 1.1165 - val_mae: 0.8349\n",
            "Epoch 585/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9745 - mae: 0.7890 - val_loss: 1.2376 - val_mae: 0.8446\n",
            "Epoch 586/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9806 - mae: 0.8029 - val_loss: 1.1194 - val_mae: 0.8103\n",
            "Epoch 587/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9841 - mae: 0.7910 - val_loss: 1.1255 - val_mae: 0.8443\n",
            "Epoch 588/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0147 - mae: 0.8009 - val_loss: 1.1099 - val_mae: 0.8197\n",
            "Epoch 589/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0193 - mae: 0.8081 - val_loss: 1.1087 - val_mae: 0.8152\n",
            "Epoch 590/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9656 - mae: 0.7857 - val_loss: 1.2392 - val_mae: 0.8483\n",
            "Epoch 591/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9910 - mae: 0.8004 - val_loss: 1.1529 - val_mae: 0.8543\n",
            "Epoch 592/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0023 - mae: 0.8035 - val_loss: 1.1227 - val_mae: 0.8414\n",
            "Epoch 593/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0097 - mae: 0.8064 - val_loss: 1.1195 - val_mae: 0.8360\n",
            "Epoch 594/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9857 - mae: 0.8026 - val_loss: 1.1111 - val_mae: 0.8085\n",
            "Epoch 595/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9770 - mae: 0.8047 - val_loss: 1.1041 - val_mae: 0.8121\n",
            "Epoch 596/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0112 - mae: 0.8020 - val_loss: 1.1092 - val_mae: 0.8127\n",
            "Epoch 597/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9686 - mae: 0.7930 - val_loss: 1.2510 - val_mae: 0.8480\n",
            "Epoch 598/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0056 - mae: 0.8164 - val_loss: 1.1263 - val_mae: 0.8395\n",
            "Epoch 599/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9837 - mae: 0.7989 - val_loss: 1.1415 - val_mae: 0.8160\n",
            "Epoch 600/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9785 - mae: 0.7942 - val_loss: 1.1321 - val_mae: 0.8420\n",
            "Epoch 601/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9695 - mae: 0.7929 - val_loss: 1.1462 - val_mae: 0.8527\n",
            "Epoch 602/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9947 - mae: 0.7960 - val_loss: 1.2881 - val_mae: 0.9162\n",
            "Epoch 603/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9902 - mae: 0.7982 - val_loss: 1.1421 - val_mae: 0.8565\n",
            "Epoch 604/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9846 - mae: 0.7910 - val_loss: 1.1316 - val_mae: 0.8481\n",
            "Epoch 605/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9779 - mae: 0.7939 - val_loss: 1.2865 - val_mae: 0.9174\n",
            "Epoch 606/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0084 - mae: 0.8125 - val_loss: 1.2687 - val_mae: 0.9110\n",
            "Epoch 607/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0193 - mae: 0.8111 - val_loss: 1.1502 - val_mae: 0.8577\n",
            "Epoch 608/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9972 - mae: 0.8026 - val_loss: 1.1803 - val_mae: 0.8679\n",
            "Epoch 609/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9933 - mae: 0.7903 - val_loss: 1.1643 - val_mae: 0.8189\n",
            "Epoch 610/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9978 - mae: 0.7967 - val_loss: 1.3313 - val_mae: 0.9336\n",
            "Epoch 611/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9953 - mae: 0.8058 - val_loss: 1.3018 - val_mae: 0.9229\n",
            "Epoch 612/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9807 - mae: 0.7983 - val_loss: 1.1122 - val_mae: 0.8223\n",
            "Epoch 613/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9741 - mae: 0.7944 - val_loss: 1.3678 - val_mae: 0.9475\n",
            "Epoch 614/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9801 - mae: 0.7910 - val_loss: 1.1460 - val_mae: 0.8152\n",
            "Epoch 615/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9633 - mae: 0.7881 - val_loss: 1.1184 - val_mae: 0.8364\n",
            "Epoch 616/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9804 - mae: 0.7974 - val_loss: 1.2918 - val_mae: 0.9201\n",
            "Epoch 617/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9949 - mae: 0.7991 - val_loss: 1.1142 - val_mae: 0.8325\n",
            "Epoch 618/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9739 - mae: 0.7997 - val_loss: 1.1506 - val_mae: 0.8152\n",
            "Epoch 619/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9803 - mae: 0.7908 - val_loss: 1.1596 - val_mae: 0.8206\n",
            "Epoch 620/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0211 - mae: 0.8002 - val_loss: 1.1196 - val_mae: 0.8144\n",
            "Epoch 621/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0090 - mae: 0.8027 - val_loss: 1.1134 - val_mae: 0.8177\n",
            "Epoch 622/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9935 - mae: 0.8022 - val_loss: 1.1447 - val_mae: 0.8513\n",
            "Epoch 623/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9753 - mae: 0.7892 - val_loss: 1.2226 - val_mae: 0.8387\n",
            "Epoch 624/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0064 - mae: 0.7996 - val_loss: 1.1161 - val_mae: 0.8208\n",
            "Epoch 625/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0126 - mae: 0.7994 - val_loss: 1.2426 - val_mae: 0.8430\n",
            "Epoch 626/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9745 - mae: 0.7995 - val_loss: 1.1127 - val_mae: 0.8147\n",
            "Epoch 627/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9969 - mae: 0.8018 - val_loss: 1.1709 - val_mae: 0.8642\n",
            "Epoch 628/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9847 - mae: 0.7923 - val_loss: 1.1267 - val_mae: 0.8438\n",
            "Epoch 629/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9803 - mae: 0.8006 - val_loss: 1.1681 - val_mae: 0.8192\n",
            "Epoch 630/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9979 - mae: 0.8016 - val_loss: 1.1108 - val_mae: 0.8092\n",
            "Epoch 631/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9960 - mae: 0.7953 - val_loss: 1.1305 - val_mae: 0.8167\n",
            "Epoch 632/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9873 - mae: 0.7965 - val_loss: 1.1180 - val_mae: 0.8360\n",
            "Epoch 633/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0048 - mae: 0.8000 - val_loss: 1.1266 - val_mae: 0.8466\n",
            "Epoch 634/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9938 - mae: 0.8009 - val_loss: 1.3050 - val_mae: 0.9259\n",
            "Epoch 635/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9663 - mae: 0.7922 - val_loss: 1.2602 - val_mae: 0.8528\n",
            "Epoch 636/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0024 - mae: 0.8040 - val_loss: 1.1912 - val_mae: 0.8727\n",
            "Epoch 637/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9671 - mae: 0.7830 - val_loss: 1.1230 - val_mae: 0.8066\n",
            "Epoch 638/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9963 - mae: 0.7989 - val_loss: 1.1021 - val_mae: 0.8217\n",
            "Epoch 639/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9944 - mae: 0.7899 - val_loss: 1.1225 - val_mae: 0.8079\n",
            "Epoch 640/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9885 - mae: 0.7982 - val_loss: 1.1311 - val_mae: 0.8447\n",
            "Epoch 641/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9957 - mae: 0.8009 - val_loss: 1.1358 - val_mae: 0.8104\n",
            "Epoch 642/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0097 - mae: 0.8056 - val_loss: 1.2675 - val_mae: 0.8563\n",
            "Epoch 643/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9678 - mae: 0.7870 - val_loss: 1.1417 - val_mae: 0.8519\n",
            "Epoch 644/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9861 - mae: 0.7996 - val_loss: 1.1445 - val_mae: 0.8524\n",
            "Epoch 645/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9970 - mae: 0.8046 - val_loss: 1.1280 - val_mae: 0.8097\n",
            "Epoch 646/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9709 - mae: 0.7869 - val_loss: 1.1181 - val_mae: 0.8278\n",
            "Epoch 647/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0028 - mae: 0.8005 - val_loss: 1.2969 - val_mae: 0.9210\n",
            "Epoch 648/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9708 - mae: 0.7920 - val_loss: 1.2603 - val_mae: 0.8532\n",
            "Epoch 649/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0008 - mae: 0.8087 - val_loss: 1.1426 - val_mae: 0.8530\n",
            "Epoch 650/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0004 - mae: 0.7939 - val_loss: 1.1297 - val_mae: 0.8468\n",
            "Epoch 651/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9565 - mae: 0.7935 - val_loss: 1.1232 - val_mae: 0.8384\n",
            "Epoch 652/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9847 - mae: 0.7924 - val_loss: 1.3787 - val_mae: 0.9514\n",
            "Epoch 653/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9778 - mae: 0.7924 - val_loss: 1.1114 - val_mae: 0.8119\n",
            "Epoch 654/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0083 - mae: 0.8062 - val_loss: 1.3097 - val_mae: 0.9270\n",
            "Epoch 655/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9763 - mae: 0.7916 - val_loss: 1.1186 - val_mae: 0.8405\n",
            "Epoch 656/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9795 - mae: 0.7992 - val_loss: 1.2173 - val_mae: 0.8840\n",
            "Epoch 657/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0121 - mae: 0.8032 - val_loss: 1.1690 - val_mae: 0.8635\n",
            "Epoch 658/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0027 - mae: 0.8010 - val_loss: 1.1428 - val_mae: 0.8517\n",
            "Epoch 659/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9838 - mae: 0.7947 - val_loss: 1.2222 - val_mae: 0.8863\n",
            "Epoch 660/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9622 - mae: 0.7941 - val_loss: 1.4972 - val_mae: 0.9919\n",
            "Epoch 661/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9834 - mae: 0.7881 - val_loss: 1.1855 - val_mae: 0.8255\n",
            "Epoch 662/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0243 - mae: 0.8086 - val_loss: 1.1246 - val_mae: 0.8160\n",
            "Epoch 663/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9698 - mae: 0.7910 - val_loss: 1.1057 - val_mae: 0.8190\n",
            "Epoch 664/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0008 - mae: 0.7967 - val_loss: 1.1136 - val_mae: 0.8187\n",
            "Epoch 665/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9878 - mae: 0.8091 - val_loss: 1.1285 - val_mae: 0.8331\n",
            "Epoch 666/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9776 - mae: 0.7901 - val_loss: 1.1106 - val_mae: 0.8207\n",
            "Epoch 667/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9801 - mae: 0.7935 - val_loss: 1.2250 - val_mae: 0.8915\n",
            "Epoch 668/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9984 - mae: 0.7973 - val_loss: 1.1223 - val_mae: 0.8090\n",
            "Epoch 669/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0082 - mae: 0.7910 - val_loss: 1.1255 - val_mae: 0.8159\n",
            "Epoch 670/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9865 - mae: 0.7966 - val_loss: 1.1122 - val_mae: 0.8253\n",
            "Epoch 671/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9815 - mae: 0.7965 - val_loss: 1.1324 - val_mae: 0.8479\n",
            "Epoch 672/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0174 - mae: 0.8008 - val_loss: 1.2545 - val_mae: 0.9044\n",
            "Epoch 673/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9726 - mae: 0.7933 - val_loss: 1.1271 - val_mae: 0.8163\n",
            "Epoch 674/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9919 - mae: 0.7948 - val_loss: 1.1067 - val_mae: 0.8159\n",
            "Epoch 675/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9890 - mae: 0.7942 - val_loss: 1.1288 - val_mae: 0.8420\n",
            "Epoch 676/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9730 - mae: 0.7928 - val_loss: 1.2287 - val_mae: 0.8923\n",
            "Epoch 677/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9872 - mae: 0.7984 - val_loss: 1.1519 - val_mae: 0.8533\n",
            "Epoch 678/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9974 - mae: 0.7960 - val_loss: 1.1274 - val_mae: 0.8160\n",
            "Epoch 679/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9801 - mae: 0.7945 - val_loss: 1.1488 - val_mae: 0.8132\n",
            "Epoch 680/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9979 - mae: 0.7918 - val_loss: 1.4415 - val_mae: 0.9729\n",
            "Epoch 681/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9791 - mae: 0.7833 - val_loss: 1.1543 - val_mae: 0.8579\n",
            "Epoch 682/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0010 - mae: 0.7955 - val_loss: 1.1980 - val_mae: 0.8807\n",
            "Epoch 683/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9978 - mae: 0.7997 - val_loss: 1.1235 - val_mae: 0.8430\n",
            "Epoch 684/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0082 - mae: 0.8144 - val_loss: 1.1153 - val_mae: 0.8238\n",
            "Epoch 685/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9931 - mae: 0.7973 - val_loss: 1.2017 - val_mae: 0.8814\n",
            "Epoch 686/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9837 - mae: 0.7910 - val_loss: 1.1415 - val_mae: 0.8531\n",
            "Epoch 687/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0051 - mae: 0.8131 - val_loss: 1.1152 - val_mae: 0.8093\n",
            "Epoch 688/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9797 - mae: 0.7965 - val_loss: 1.2117 - val_mae: 0.8867\n",
            "Epoch 689/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9751 - mae: 0.7947 - val_loss: 1.1624 - val_mae: 0.8176\n",
            "Epoch 690/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9932 - mae: 0.7976 - val_loss: 1.5036 - val_mae: 0.9945\n",
            "Epoch 691/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0052 - mae: 0.7885 - val_loss: 1.2018 - val_mae: 0.8787\n",
            "Epoch 692/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9846 - mae: 0.7885 - val_loss: 1.1185 - val_mae: 0.8080\n",
            "Epoch 693/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0133 - mae: 0.8048 - val_loss: 1.1220 - val_mae: 0.8250\n",
            "Epoch 694/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9882 - mae: 0.7985 - val_loss: 1.1269 - val_mae: 0.8407\n",
            "Epoch 695/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9951 - mae: 0.7974 - val_loss: 1.1876 - val_mae: 0.8732\n",
            "Epoch 696/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9779 - mae: 0.8002 - val_loss: 1.1422 - val_mae: 0.8545\n",
            "Epoch 697/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0151 - mae: 0.8069 - val_loss: 1.1390 - val_mae: 0.8139\n",
            "Epoch 698/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9843 - mae: 0.8017 - val_loss: 1.1172 - val_mae: 0.8345\n",
            "Epoch 699/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0122 - mae: 0.8038 - val_loss: 1.1639 - val_mae: 0.8218\n",
            "Epoch 700/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9673 - mae: 0.7894 - val_loss: 1.1436 - val_mae: 0.8546\n",
            "Epoch 701/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0007 - mae: 0.7918 - val_loss: 1.2695 - val_mae: 0.9064\n",
            "Epoch 702/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9725 - mae: 0.7873 - val_loss: 1.1894 - val_mae: 0.8292\n",
            "Epoch 703/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9549 - mae: 0.7923 - val_loss: 1.1199 - val_mae: 0.8173\n",
            "Epoch 704/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9777 - mae: 0.7887 - val_loss: 1.3545 - val_mae: 0.9430\n",
            "Epoch 705/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9987 - mae: 0.7951 - val_loss: 1.1448 - val_mae: 0.8461\n",
            "Epoch 706/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9902 - mae: 0.7919 - val_loss: 1.1161 - val_mae: 0.8098\n",
            "Epoch 707/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0215 - mae: 0.8113 - val_loss: 1.1143 - val_mae: 0.8305\n",
            "Epoch 708/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9796 - mae: 0.8001 - val_loss: 1.2442 - val_mae: 0.8966\n",
            "Epoch 709/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0106 - mae: 0.8019 - val_loss: 1.2607 - val_mae: 0.8547\n",
            "Epoch 710/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9834 - mae: 0.7960 - val_loss: 1.2626 - val_mae: 0.9068\n",
            "Epoch 711/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9951 - mae: 0.7991 - val_loss: 1.1253 - val_mae: 0.8243\n",
            "Epoch 712/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9790 - mae: 0.8016 - val_loss: 1.1319 - val_mae: 0.8361\n",
            "Epoch 713/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9840 - mae: 0.7988 - val_loss: 1.1153 - val_mae: 0.8099\n",
            "Epoch 714/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9669 - mae: 0.7891 - val_loss: 1.1603 - val_mae: 0.8564\n",
            "Epoch 715/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9802 - mae: 0.7998 - val_loss: 1.1402 - val_mae: 0.8462\n",
            "Epoch 716/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0094 - mae: 0.8001 - val_loss: 1.1714 - val_mae: 0.8655\n",
            "Epoch 717/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9731 - mae: 0.7945 - val_loss: 1.1997 - val_mae: 0.8822\n",
            "Epoch 718/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0051 - mae: 0.8051 - val_loss: 1.2422 - val_mae: 0.8997\n",
            "Epoch 719/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9757 - mae: 0.7908 - val_loss: 1.1161 - val_mae: 0.8355\n",
            "Epoch 720/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0072 - mae: 0.8070 - val_loss: 1.1290 - val_mae: 0.8397\n",
            "Epoch 721/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9885 - mae: 0.7842 - val_loss: 1.1422 - val_mae: 0.8505\n",
            "Epoch 722/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9840 - mae: 0.7989 - val_loss: 1.1231 - val_mae: 0.8375\n",
            "Epoch 723/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9806 - mae: 0.7913 - val_loss: 1.1663 - val_mae: 0.8235\n",
            "Epoch 724/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9994 - mae: 0.7996 - val_loss: 1.1499 - val_mae: 0.8525\n",
            "Epoch 725/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9603 - mae: 0.7912 - val_loss: 1.3103 - val_mae: 0.9259\n",
            "Epoch 726/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0023 - mae: 0.8023 - val_loss: 1.1757 - val_mae: 0.8650\n",
            "Epoch 727/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0045 - mae: 0.8052 - val_loss: 1.4871 - val_mae: 0.9898\n",
            "Epoch 728/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9941 - mae: 0.7951 - val_loss: 1.1169 - val_mae: 0.8317\n",
            "Epoch 729/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9908 - mae: 0.8001 - val_loss: 1.1275 - val_mae: 0.8086\n",
            "Epoch 730/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9969 - mae: 0.8017 - val_loss: 1.1085 - val_mae: 0.8099\n",
            "Epoch 731/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9924 - mae: 0.7945 - val_loss: 1.2846 - val_mae: 0.8606\n",
            "Epoch 732/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9840 - mae: 0.7844 - val_loss: 1.2355 - val_mae: 0.8456\n",
            "Epoch 733/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9941 - mae: 0.7922 - val_loss: 1.5522 - val_mae: 0.9527\n",
            "Epoch 734/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9919 - mae: 0.8046 - val_loss: 1.1414 - val_mae: 0.8508\n",
            "Epoch 735/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9718 - mae: 0.7926 - val_loss: 1.2894 - val_mae: 0.9198\n",
            "Epoch 736/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0138 - mae: 0.8072 - val_loss: 1.1062 - val_mae: 0.8225\n",
            "Epoch 737/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9943 - mae: 0.8016 - val_loss: 1.3170 - val_mae: 0.8738\n",
            "Epoch 738/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0020 - mae: 0.7980 - val_loss: 1.1099 - val_mae: 0.8245\n",
            "Epoch 739/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9932 - mae: 0.7993 - val_loss: 1.1106 - val_mae: 0.8305\n",
            "Epoch 740/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0008 - mae: 0.7978 - val_loss: 1.1442 - val_mae: 0.8508\n",
            "Epoch 741/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9836 - mae: 0.7977 - val_loss: 1.1142 - val_mae: 0.8319\n",
            "Epoch 742/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0212 - mae: 0.8103 - val_loss: 1.1088 - val_mae: 0.8188\n",
            "Epoch 743/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9880 - mae: 0.7981 - val_loss: 1.1402 - val_mae: 0.8456\n",
            "Epoch 744/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9891 - mae: 0.7975 - val_loss: 1.1854 - val_mae: 0.8303\n",
            "Epoch 745/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0106 - mae: 0.8030 - val_loss: 1.1047 - val_mae: 0.8178\n",
            "Epoch 746/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9851 - mae: 0.8003 - val_loss: 1.1857 - val_mae: 0.8279\n",
            "Epoch 747/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0297 - mae: 0.8127 - val_loss: 1.2006 - val_mae: 0.8822\n",
            "Epoch 748/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9845 - mae: 0.7984 - val_loss: 1.1150 - val_mae: 0.8150\n",
            "Epoch 749/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9701 - mae: 0.7883 - val_loss: 1.1070 - val_mae: 0.8232\n",
            "Epoch 750/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9628 - mae: 0.7805 - val_loss: 1.2174 - val_mae: 0.8836\n",
            "Epoch 751/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9717 - mae: 0.7861 - val_loss: 1.1150 - val_mae: 0.8138\n",
            "Epoch 752/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9859 - mae: 0.7981 - val_loss: 1.1087 - val_mae: 0.8284\n",
            "Epoch 753/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9520 - mae: 0.7887 - val_loss: 1.1084 - val_mae: 0.8372\n",
            "Epoch 754/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9957 - mae: 0.7998 - val_loss: 1.1115 - val_mae: 0.8093\n",
            "Epoch 755/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9706 - mae: 0.7930 - val_loss: 1.1379 - val_mae: 0.8179\n",
            "Epoch 756/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9897 - mae: 0.8087 - val_loss: 1.1956 - val_mae: 0.8771\n",
            "Epoch 757/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9525 - mae: 0.7809 - val_loss: 1.1055 - val_mae: 0.8139\n",
            "Epoch 758/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0244 - mae: 0.8130 - val_loss: 1.1048 - val_mae: 0.8237\n",
            "Epoch 759/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9395 - mae: 0.7818 - val_loss: 1.2161 - val_mae: 0.8880\n",
            "Epoch 760/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0110 - mae: 0.7998 - val_loss: 1.1325 - val_mae: 0.8125\n",
            "Epoch 761/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9756 - mae: 0.7958 - val_loss: 1.1123 - val_mae: 0.8101\n",
            "Epoch 762/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9886 - mae: 0.7990 - val_loss: 1.1130 - val_mae: 0.8146\n",
            "Epoch 763/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9750 - mae: 0.7880 - val_loss: 1.1832 - val_mae: 0.8272\n",
            "Epoch 764/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0011 - mae: 0.8059 - val_loss: 1.1290 - val_mae: 0.8119\n",
            "Epoch 765/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9817 - mae: 0.7919 - val_loss: 1.2171 - val_mae: 0.8425\n",
            "Epoch 766/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0107 - mae: 0.8061 - val_loss: 1.1097 - val_mae: 0.8158\n",
            "Epoch 767/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9958 - mae: 0.8003 - val_loss: 1.1081 - val_mae: 0.8231\n",
            "Epoch 768/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0040 - mae: 0.7969 - val_loss: 1.1159 - val_mae: 0.8202\n",
            "Epoch 769/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9945 - mae: 0.7955 - val_loss: 1.1144 - val_mae: 0.8314\n",
            "Epoch 770/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9811 - mae: 0.7914 - val_loss: 1.1290 - val_mae: 0.8115\n",
            "Epoch 771/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0243 - mae: 0.8043 - val_loss: 1.1736 - val_mae: 0.8625\n",
            "Epoch 772/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9573 - mae: 0.7891 - val_loss: 1.4274 - val_mae: 0.9670\n",
            "Epoch 773/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0053 - mae: 0.8040 - val_loss: 1.1355 - val_mae: 0.8126\n",
            "Epoch 774/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9968 - mae: 0.8056 - val_loss: 1.1095 - val_mae: 0.8160\n",
            "Epoch 775/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9986 - mae: 0.8033 - val_loss: 1.1153 - val_mae: 0.8121\n",
            "Epoch 776/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9825 - mae: 0.7976 - val_loss: 1.1745 - val_mae: 0.8694\n",
            "Epoch 777/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9826 - mae: 0.7946 - val_loss: 1.1298 - val_mae: 0.8457\n",
            "Epoch 778/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9526 - mae: 0.7867 - val_loss: 1.1705 - val_mae: 0.8689\n",
            "Epoch 779/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9979 - mae: 0.7960 - val_loss: 1.1193 - val_mae: 0.8160\n",
            "Epoch 780/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0227 - mae: 0.8111 - val_loss: 1.2707 - val_mae: 0.8567\n",
            "Epoch 781/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9906 - mae: 0.8009 - val_loss: 1.1108 - val_mae: 0.8213\n",
            "Epoch 782/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9864 - mae: 0.7976 - val_loss: 1.1149 - val_mae: 0.8367\n",
            "Epoch 783/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9924 - mae: 0.7935 - val_loss: 1.1793 - val_mae: 0.8256\n",
            "Epoch 784/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9537 - mae: 0.7870 - val_loss: 1.2745 - val_mae: 0.9101\n",
            "Epoch 785/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9847 - mae: 0.7962 - val_loss: 1.1487 - val_mae: 0.8212\n",
            "Epoch 786/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9799 - mae: 0.7968 - val_loss: 1.2375 - val_mae: 0.9007\n",
            "Epoch 787/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9848 - mae: 0.7927 - val_loss: 1.1682 - val_mae: 0.8636\n",
            "Epoch 788/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9864 - mae: 0.8057 - val_loss: 1.1262 - val_mae: 0.8329\n",
            "Epoch 789/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9903 - mae: 0.7959 - val_loss: 1.1277 - val_mae: 0.8083\n",
            "Epoch 790/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9703 - mae: 0.7828 - val_loss: 1.1161 - val_mae: 0.8252\n",
            "Epoch 791/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9756 - mae: 0.7957 - val_loss: 1.2158 - val_mae: 0.8902\n",
            "Epoch 792/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9849 - mae: 0.7986 - val_loss: 1.1106 - val_mae: 0.8147\n",
            "Epoch 793/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9734 - mae: 0.7905 - val_loss: 1.1188 - val_mae: 0.8417\n",
            "Epoch 794/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0235 - mae: 0.8065 - val_loss: 1.1282 - val_mae: 0.8140\n",
            "Epoch 795/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9847 - mae: 0.8009 - val_loss: 1.1138 - val_mae: 0.8347\n",
            "Epoch 796/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9688 - mae: 0.7908 - val_loss: 1.1152 - val_mae: 0.8335\n",
            "Epoch 797/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9826 - mae: 0.7844 - val_loss: 1.1410 - val_mae: 0.8484\n",
            "Epoch 798/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9925 - mae: 0.7931 - val_loss: 1.3138 - val_mae: 0.9295\n",
            "Epoch 799/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9892 - mae: 0.8039 - val_loss: 1.1146 - val_mae: 0.8357\n",
            "Epoch 800/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9804 - mae: 0.7998 - val_loss: 1.1092 - val_mae: 0.8139\n",
            "Epoch 801/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9914 - mae: 0.7926 - val_loss: 1.4826 - val_mae: 0.9304\n",
            "Epoch 802/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0040 - mae: 0.8032 - val_loss: 1.1185 - val_mae: 0.8138\n",
            "Epoch 803/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9885 - mae: 0.7935 - val_loss: 1.2466 - val_mae: 0.9004\n",
            "Epoch 804/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0170 - mae: 0.8090 - val_loss: 1.4169 - val_mae: 0.9100\n",
            "Epoch 805/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9916 - mae: 0.8035 - val_loss: 1.2200 - val_mae: 0.8884\n",
            "Epoch 806/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9882 - mae: 0.7963 - val_loss: 1.4545 - val_mae: 0.9780\n",
            "Epoch 807/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9907 - mae: 0.8021 - val_loss: 1.1221 - val_mae: 0.8389\n",
            "Epoch 808/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9733 - mae: 0.7845 - val_loss: 1.1634 - val_mae: 0.8563\n",
            "Epoch 809/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9918 - mae: 0.8061 - val_loss: 1.3541 - val_mae: 0.8866\n",
            "Epoch 810/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9897 - mae: 0.8021 - val_loss: 1.1389 - val_mae: 0.8482\n",
            "Epoch 811/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9539 - mae: 0.7815 - val_loss: 1.2997 - val_mae: 0.9224\n",
            "Epoch 812/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9997 - mae: 0.7986 - val_loss: 1.3007 - val_mae: 0.9236\n",
            "Epoch 813/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0100 - mae: 0.8067 - val_loss: 1.1120 - val_mae: 0.8302\n",
            "Epoch 814/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9518 - mae: 0.7797 - val_loss: 1.1157 - val_mae: 0.8313\n",
            "Epoch 815/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9751 - mae: 0.7917 - val_loss: 1.1167 - val_mae: 0.8323\n",
            "Epoch 816/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9921 - mae: 0.8004 - val_loss: 1.1232 - val_mae: 0.8138\n",
            "Epoch 817/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9457 - mae: 0.7889 - val_loss: 1.1091 - val_mae: 0.8220\n",
            "Epoch 818/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9651 - mae: 0.7834 - val_loss: 1.2502 - val_mae: 0.8450\n",
            "Epoch 819/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9723 - mae: 0.7845 - val_loss: 1.2045 - val_mae: 0.8334\n",
            "Epoch 820/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9923 - mae: 0.7977 - val_loss: 1.1246 - val_mae: 0.8412\n",
            "Epoch 821/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9674 - mae: 0.7809 - val_loss: 1.2075 - val_mae: 0.8369\n",
            "Epoch 822/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9962 - mae: 0.8042 - val_loss: 1.1327 - val_mae: 0.8488\n",
            "Epoch 823/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9768 - mae: 0.7896 - val_loss: 1.1877 - val_mae: 0.8768\n",
            "Epoch 824/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9974 - mae: 0.7960 - val_loss: 1.1106 - val_mae: 0.8104\n",
            "Epoch 825/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0024 - mae: 0.7948 - val_loss: 1.3027 - val_mae: 0.8672\n",
            "Epoch 826/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0033 - mae: 0.7926 - val_loss: 1.2368 - val_mae: 0.8968\n",
            "Epoch 827/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9711 - mae: 0.7861 - val_loss: 1.1396 - val_mae: 0.8123\n",
            "Epoch 828/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9830 - mae: 0.7868 - val_loss: 1.1150 - val_mae: 0.8367\n",
            "Epoch 829/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9715 - mae: 0.7938 - val_loss: 1.2649 - val_mae: 0.9094\n",
            "Epoch 830/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9984 - mae: 0.7966 - val_loss: 1.1234 - val_mae: 0.8219\n",
            "Epoch 831/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9834 - mae: 0.7929 - val_loss: 1.1077 - val_mae: 0.8215\n",
            "Epoch 832/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9826 - mae: 0.7988 - val_loss: 1.1340 - val_mae: 0.8135\n",
            "Epoch 833/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0100 - mae: 0.7963 - val_loss: 1.3385 - val_mae: 0.8786\n",
            "Epoch 834/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9920 - mae: 0.7986 - val_loss: 1.1682 - val_mae: 0.8668\n",
            "Epoch 835/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9755 - mae: 0.7835 - val_loss: 1.4670 - val_mae: 0.9250\n",
            "Epoch 836/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9823 - mae: 0.7950 - val_loss: 1.1514 - val_mae: 0.8241\n",
            "Epoch 837/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0019 - mae: 0.8027 - val_loss: 1.2837 - val_mae: 0.9150\n",
            "Epoch 838/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9928 - mae: 0.8023 - val_loss: 1.1290 - val_mae: 0.8421\n",
            "Epoch 839/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9996 - mae: 0.7975 - val_loss: 1.1673 - val_mae: 0.8172\n",
            "Epoch 840/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9501 - mae: 0.7861 - val_loss: 1.1186 - val_mae: 0.8247\n",
            "Epoch 841/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9754 - mae: 0.7940 - val_loss: 1.1344 - val_mae: 0.8467\n",
            "Epoch 842/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9954 - mae: 0.8078 - val_loss: 1.1731 - val_mae: 0.8233\n",
            "Epoch 843/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9743 - mae: 0.7868 - val_loss: 1.2176 - val_mae: 0.8883\n",
            "Epoch 844/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9928 - mae: 0.7973 - val_loss: 1.1756 - val_mae: 0.8259\n",
            "Epoch 845/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9829 - mae: 0.7958 - val_loss: 1.1255 - val_mae: 0.8380\n",
            "Epoch 846/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9959 - mae: 0.7824 - val_loss: 1.1494 - val_mae: 0.8172\n",
            "Epoch 847/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9969 - mae: 0.8019 - val_loss: 1.1550 - val_mae: 0.8537\n",
            "Epoch 848/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0163 - mae: 0.8052 - val_loss: 1.1127 - val_mae: 0.8170\n",
            "Epoch 849/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9870 - mae: 0.7978 - val_loss: 1.1174 - val_mae: 0.8305\n",
            "Epoch 850/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9935 - mae: 0.8062 - val_loss: 1.1471 - val_mae: 0.8534\n",
            "Epoch 851/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0048 - mae: 0.7993 - val_loss: 1.1680 - val_mae: 0.8213\n",
            "Epoch 852/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0048 - mae: 0.7956 - val_loss: 1.2184 - val_mae: 0.8385\n",
            "Epoch 853/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0016 - mae: 0.8011 - val_loss: 1.1316 - val_mae: 0.8458\n",
            "Epoch 854/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9923 - mae: 0.7938 - val_loss: 1.1142 - val_mae: 0.8161\n",
            "Epoch 855/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0002 - mae: 0.7986 - val_loss: 1.1066 - val_mae: 0.8269\n",
            "Epoch 856/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9761 - mae: 0.7864 - val_loss: 1.2109 - val_mae: 0.8338\n",
            "Epoch 857/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9744 - mae: 0.7865 - val_loss: 1.2195 - val_mae: 0.8881\n",
            "Epoch 858/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9980 - mae: 0.7962 - val_loss: 1.1763 - val_mae: 0.8683\n",
            "Epoch 859/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0049 - mae: 0.7999 - val_loss: 1.2026 - val_mae: 0.8831\n",
            "Epoch 860/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9705 - mae: 0.7870 - val_loss: 1.1113 - val_mae: 0.8141\n",
            "Epoch 861/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0017 - mae: 0.7955 - val_loss: 1.1832 - val_mae: 0.8749\n",
            "Epoch 862/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9733 - mae: 0.7945 - val_loss: 1.2686 - val_mae: 0.9144\n",
            "Epoch 863/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9869 - mae: 0.7967 - val_loss: 1.1129 - val_mae: 0.8360\n",
            "Epoch 864/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9893 - mae: 0.7973 - val_loss: 1.1244 - val_mae: 0.8184\n",
            "Epoch 865/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0214 - mae: 0.8080 - val_loss: 1.1158 - val_mae: 0.8189\n",
            "Epoch 866/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9825 - mae: 0.7903 - val_loss: 1.3474 - val_mae: 0.8835\n",
            "Epoch 867/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9960 - mae: 0.7976 - val_loss: 1.1165 - val_mae: 0.8370\n",
            "Epoch 868/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0014 - mae: 0.7927 - val_loss: 1.1234 - val_mae: 0.8162\n",
            "Epoch 869/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9813 - mae: 0.7853 - val_loss: 1.2921 - val_mae: 0.9211\n",
            "Epoch 870/1000\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.9505 - mae: 0.7817 - val_loss: 1.2009 - val_mae: 0.8792\n",
            "Epoch 871/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9923 - mae: 0.7930 - val_loss: 1.3176 - val_mae: 0.9278\n",
            "Epoch 872/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9839 - mae: 0.7948 - val_loss: 1.1387 - val_mae: 0.8411\n",
            "Epoch 873/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9961 - mae: 0.8060 - val_loss: 1.1972 - val_mae: 0.8779\n",
            "Epoch 874/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9654 - mae: 0.7842 - val_loss: 1.3092 - val_mae: 0.9256\n",
            "Epoch 875/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9825 - mae: 0.7966 - val_loss: 1.1499 - val_mae: 0.8501\n",
            "Epoch 876/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9829 - mae: 0.7869 - val_loss: 1.1446 - val_mae: 0.8525\n",
            "Epoch 877/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0042 - mae: 0.8025 - val_loss: 1.5158 - val_mae: 0.9989\n",
            "Epoch 878/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9955 - mae: 0.7910 - val_loss: 1.6889 - val_mae: 1.0591\n",
            "Epoch 879/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9904 - mae: 0.7908 - val_loss: 1.1113 - val_mae: 0.8283\n",
            "Epoch 880/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0007 - mae: 0.7949 - val_loss: 1.2535 - val_mae: 0.9039\n",
            "Epoch 881/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9634 - mae: 0.7912 - val_loss: 1.1435 - val_mae: 0.8301\n",
            "Epoch 882/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9710 - mae: 0.7995 - val_loss: 1.2123 - val_mae: 0.8843\n",
            "Epoch 883/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0019 - mae: 0.8061 - val_loss: 1.1130 - val_mae: 0.8146\n",
            "Epoch 884/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9792 - mae: 0.7957 - val_loss: 1.1105 - val_mae: 0.8179\n",
            "Epoch 885/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9991 - mae: 0.7929 - val_loss: 1.1392 - val_mae: 0.8497\n",
            "Epoch 886/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9611 - mae: 0.7942 - val_loss: 1.1253 - val_mae: 0.8333\n",
            "Epoch 887/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9962 - mae: 0.8034 - val_loss: 1.2151 - val_mae: 0.8357\n",
            "Epoch 888/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9691 - mae: 0.7972 - val_loss: 1.2068 - val_mae: 0.8844\n",
            "Epoch 889/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9972 - mae: 0.7872 - val_loss: 1.1790 - val_mae: 0.8269\n",
            "Epoch 890/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0097 - mae: 0.8115 - val_loss: 1.1340 - val_mae: 0.8462\n",
            "Epoch 891/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9871 - mae: 0.8044 - val_loss: 1.1190 - val_mae: 0.8163\n",
            "Epoch 892/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9889 - mae: 0.7960 - val_loss: 1.1580 - val_mae: 0.8605\n",
            "Epoch 893/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9817 - mae: 0.7961 - val_loss: 1.2341 - val_mae: 0.8417\n",
            "Epoch 894/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9910 - mae: 0.8023 - val_loss: 1.1197 - val_mae: 0.8285\n",
            "Epoch 895/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0073 - mae: 0.7934 - val_loss: 1.1137 - val_mae: 0.8330\n",
            "Epoch 896/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9846 - mae: 0.8006 - val_loss: 1.1059 - val_mae: 0.8164\n",
            "Epoch 897/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9954 - mae: 0.7973 - val_loss: 1.4909 - val_mae: 0.9913\n",
            "Epoch 898/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9842 - mae: 0.7937 - val_loss: 1.1261 - val_mae: 0.8100\n",
            "Epoch 899/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9873 - mae: 0.7966 - val_loss: 1.1905 - val_mae: 0.8762\n",
            "Epoch 900/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0149 - mae: 0.8115 - val_loss: 1.1086 - val_mae: 0.8241\n",
            "Epoch 901/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9623 - mae: 0.7916 - val_loss: 1.1064 - val_mae: 0.8243\n",
            "Epoch 902/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9523 - mae: 0.7765 - val_loss: 1.1117 - val_mae: 0.8096\n",
            "Epoch 903/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9744 - mae: 0.7920 - val_loss: 1.1412 - val_mae: 0.8188\n",
            "Epoch 904/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9773 - mae: 0.7874 - val_loss: 1.1844 - val_mae: 0.8755\n",
            "Epoch 905/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9941 - mae: 0.7971 - val_loss: 1.1767 - val_mae: 0.8232\n",
            "Epoch 906/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9823 - mae: 0.7999 - val_loss: 1.3504 - val_mae: 0.9406\n",
            "Epoch 907/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0009 - mae: 0.8109 - val_loss: 1.1315 - val_mae: 0.8120\n",
            "Epoch 908/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9622 - mae: 0.7889 - val_loss: 1.2567 - val_mae: 0.8499\n",
            "Epoch 909/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0006 - mae: 0.8019 - val_loss: 1.2108 - val_mae: 0.8852\n",
            "Epoch 910/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0005 - mae: 0.8044 - val_loss: 1.1649 - val_mae: 0.8651\n",
            "Epoch 911/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9620 - mae: 0.7858 - val_loss: 1.1134 - val_mae: 0.8233\n",
            "Epoch 912/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9873 - mae: 0.7995 - val_loss: 1.2564 - val_mae: 0.9039\n",
            "Epoch 913/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9852 - mae: 0.7943 - val_loss: 1.1148 - val_mae: 0.8144\n",
            "Epoch 914/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9950 - mae: 0.7980 - val_loss: 1.2494 - val_mae: 0.9008\n",
            "Epoch 915/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0054 - mae: 0.8013 - val_loss: 1.1187 - val_mae: 0.8335\n",
            "Epoch 916/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9671 - mae: 0.7865 - val_loss: 1.1858 - val_mae: 0.8268\n",
            "Epoch 917/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9846 - mae: 0.7925 - val_loss: 1.1401 - val_mae: 0.8162\n",
            "Epoch 918/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9663 - mae: 0.7933 - val_loss: 1.1102 - val_mae: 0.8170\n",
            "Epoch 919/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9999 - mae: 0.7952 - val_loss: 1.1143 - val_mae: 0.8211\n",
            "Epoch 920/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0038 - mae: 0.8009 - val_loss: 1.1163 - val_mae: 0.8365\n",
            "Epoch 921/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9957 - mae: 0.8056 - val_loss: 1.1742 - val_mae: 0.8248\n",
            "Epoch 922/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9813 - mae: 0.7843 - val_loss: 1.2162 - val_mae: 0.8370\n",
            "Epoch 923/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9741 - mae: 0.7897 - val_loss: 1.1660 - val_mae: 0.8220\n",
            "Epoch 924/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9923 - mae: 0.7898 - val_loss: 1.1312 - val_mae: 0.8132\n",
            "Epoch 925/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9978 - mae: 0.7962 - val_loss: 1.2014 - val_mae: 0.8788\n",
            "Epoch 926/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9803 - mae: 0.7922 - val_loss: 1.1191 - val_mae: 0.8357\n",
            "Epoch 927/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0150 - mae: 0.8162 - val_loss: 1.1163 - val_mae: 0.8309\n",
            "Epoch 928/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9632 - mae: 0.7845 - val_loss: 1.1966 - val_mae: 0.8330\n",
            "Epoch 929/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9952 - mae: 0.8062 - val_loss: 1.2270 - val_mae: 0.8919\n",
            "Epoch 930/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9791 - mae: 0.7950 - val_loss: 1.1974 - val_mae: 0.8820\n",
            "Epoch 931/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9873 - mae: 0.7939 - val_loss: 1.1336 - val_mae: 0.8454\n",
            "Epoch 932/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0203 - mae: 0.8081 - val_loss: 1.2566 - val_mae: 0.9072\n",
            "Epoch 933/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9653 - mae: 0.7853 - val_loss: 1.1293 - val_mae: 0.8463\n",
            "Epoch 934/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0002 - mae: 0.7965 - val_loss: 1.5494 - val_mae: 0.9534\n",
            "Epoch 935/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9916 - mae: 0.7943 - val_loss: 1.1098 - val_mae: 0.8337\n",
            "Epoch 936/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0079 - mae: 0.7935 - val_loss: 1.1075 - val_mae: 0.8264\n",
            "Epoch 937/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9943 - mae: 0.7968 - val_loss: 1.1684 - val_mae: 0.8624\n",
            "Epoch 938/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9618 - mae: 0.7857 - val_loss: 1.2887 - val_mae: 0.9178\n",
            "Epoch 939/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9797 - mae: 0.7973 - val_loss: 1.1096 - val_mae: 0.8248\n",
            "Epoch 940/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0072 - mae: 0.8096 - val_loss: 1.2030 - val_mae: 0.8803\n",
            "Epoch 941/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9731 - mae: 0.8005 - val_loss: 1.1554 - val_mae: 0.8634\n",
            "Epoch 942/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0033 - mae: 0.8063 - val_loss: 1.1126 - val_mae: 0.8326\n",
            "Epoch 943/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9807 - mae: 0.7928 - val_loss: 1.1170 - val_mae: 0.8183\n",
            "Epoch 944/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9607 - mae: 0.7807 - val_loss: 1.1394 - val_mae: 0.8286\n",
            "Epoch 945/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9984 - mae: 0.7989 - val_loss: 1.1602 - val_mae: 0.8151\n",
            "Epoch 946/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9634 - mae: 0.7847 - val_loss: 1.1180 - val_mae: 0.8357\n",
            "Epoch 947/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9781 - mae: 0.7978 - val_loss: 1.1324 - val_mae: 0.8118\n",
            "Epoch 948/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9903 - mae: 0.7918 - val_loss: 1.1650 - val_mae: 0.8634\n",
            "Epoch 949/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9540 - mae: 0.7828 - val_loss: 1.3966 - val_mae: 0.9591\n",
            "Epoch 950/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9969 - mae: 0.8039 - val_loss: 1.3169 - val_mae: 0.8704\n",
            "Epoch 951/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9683 - mae: 0.7877 - val_loss: 1.4106 - val_mae: 0.9054\n",
            "Epoch 952/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0082 - mae: 0.8057 - val_loss: 1.1078 - val_mae: 0.8216\n",
            "Epoch 953/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9760 - mae: 0.7912 - val_loss: 1.1172 - val_mae: 0.8114\n",
            "Epoch 954/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9678 - mae: 0.7890 - val_loss: 1.3007 - val_mae: 0.8641\n",
            "Epoch 955/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9772 - mae: 0.8020 - val_loss: 1.1638 - val_mae: 0.8228\n",
            "Epoch 956/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9713 - mae: 0.7836 - val_loss: 1.1213 - val_mae: 0.8391\n",
            "Epoch 957/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9959 - mae: 0.7988 - val_loss: 1.1877 - val_mae: 0.8742\n",
            "Epoch 958/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9757 - mae: 0.7976 - val_loss: 1.1680 - val_mae: 0.8234\n",
            "Epoch 959/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0070 - mae: 0.7997 - val_loss: 1.1259 - val_mae: 0.8401\n",
            "Epoch 960/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0137 - mae: 0.8021 - val_loss: 1.1461 - val_mae: 0.8171\n",
            "Epoch 961/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9671 - mae: 0.7891 - val_loss: 1.1260 - val_mae: 0.8125\n",
            "Epoch 962/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9892 - mae: 0.7858 - val_loss: 1.2914 - val_mae: 0.9218\n",
            "Epoch 963/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9969 - mae: 0.7937 - val_loss: 1.1161 - val_mae: 0.8261\n",
            "Epoch 964/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9729 - mae: 0.7968 - val_loss: 1.1311 - val_mae: 0.8489\n",
            "Epoch 965/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9715 - mae: 0.7956 - val_loss: 1.1123 - val_mae: 0.8180\n",
            "Epoch 966/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0010 - mae: 0.8050 - val_loss: 1.1412 - val_mae: 0.8511\n",
            "Epoch 967/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9595 - mae: 0.7859 - val_loss: 1.1644 - val_mae: 0.8210\n",
            "Epoch 968/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0042 - mae: 0.8004 - val_loss: 1.1220 - val_mae: 0.8404\n",
            "Epoch 969/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9900 - mae: 0.7898 - val_loss: 1.1744 - val_mae: 0.8692\n",
            "Epoch 970/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9903 - mae: 0.7964 - val_loss: 1.1371 - val_mae: 0.8517\n",
            "Epoch 971/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9820 - mae: 0.7897 - val_loss: 1.1068 - val_mae: 0.8178\n",
            "Epoch 972/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9666 - mae: 0.7812 - val_loss: 1.1454 - val_mae: 0.8109\n",
            "Epoch 973/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9504 - mae: 0.7804 - val_loss: 1.4337 - val_mae: 0.9738\n",
            "Epoch 974/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9765 - mae: 0.7984 - val_loss: 1.1118 - val_mae: 0.8241\n",
            "Epoch 975/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9953 - mae: 0.8037 - val_loss: 1.1133 - val_mae: 0.8188\n",
            "Epoch 976/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9658 - mae: 0.7942 - val_loss: 1.1501 - val_mae: 0.8189\n",
            "Epoch 977/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9610 - mae: 0.7832 - val_loss: 1.1508 - val_mae: 0.8125\n",
            "Epoch 978/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0078 - mae: 0.8027 - val_loss: 1.2206 - val_mae: 0.8370\n",
            "Epoch 979/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9959 - mae: 0.8068 - val_loss: 1.1766 - val_mae: 0.8255\n",
            "Epoch 980/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9737 - mae: 0.7836 - val_loss: 1.2735 - val_mae: 0.8548\n",
            "Epoch 981/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9756 - mae: 0.7930 - val_loss: 1.1203 - val_mae: 0.8305\n",
            "Epoch 982/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9901 - mae: 0.7990 - val_loss: 1.1832 - val_mae: 0.8712\n",
            "Epoch 983/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9770 - mae: 0.7952 - val_loss: 1.1136 - val_mae: 0.8261\n",
            "Epoch 984/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0236 - mae: 0.8058 - val_loss: 1.1451 - val_mae: 0.8496\n",
            "Epoch 985/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9592 - mae: 0.7824 - val_loss: 1.1478 - val_mae: 0.8489\n",
            "Epoch 986/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9998 - mae: 0.7998 - val_loss: 1.2703 - val_mae: 0.8529\n",
            "Epoch 987/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9563 - mae: 0.7878 - val_loss: 1.3272 - val_mae: 0.9334\n",
            "Epoch 988/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9951 - mae: 0.7957 - val_loss: 1.1424 - val_mae: 0.8518\n",
            "Epoch 989/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9969 - mae: 0.7959 - val_loss: 1.1042 - val_mae: 0.8148\n",
            "Epoch 990/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9673 - mae: 0.7851 - val_loss: 1.1087 - val_mae: 0.8282\n",
            "Epoch 991/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9807 - mae: 0.7971 - val_loss: 1.1084 - val_mae: 0.8094\n",
            "Epoch 992/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9640 - mae: 0.7868 - val_loss: 1.1089 - val_mae: 0.8116\n",
            "Epoch 993/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9810 - mae: 0.7932 - val_loss: 1.3379 - val_mae: 0.9389\n",
            "Epoch 994/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9943 - mae: 0.8014 - val_loss: 1.1724 - val_mae: 0.8666\n",
            "Epoch 995/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9761 - mae: 0.7889 - val_loss: 1.2465 - val_mae: 0.9023\n",
            "Epoch 996/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9952 - mae: 0.7978 - val_loss: 1.1329 - val_mae: 0.8376\n",
            "Epoch 997/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9795 - mae: 0.7940 - val_loss: 1.1309 - val_mae: 0.8112\n",
            "Epoch 998/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0119 - mae: 0.8053 - val_loss: 1.1198 - val_mae: 0.8395\n",
            "Epoch 999/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9954 - mae: 0.7972 - val_loss: 1.1079 - val_mae: 0.8170\n",
            "Epoch 1000/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9630 - mae: 0.7870 - val_loss: 1.1279 - val_mae: 0.8283\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h86FEo80XhW",
        "colab_type": "text"
      },
      "source": [
        "## Convert the Tensorflow Model to Tensorflow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egny1KLL0Wm0",
        "colab_type": "code",
        "outputId": "22601a85-82bd-43f7-9b0d-963e393ec92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "open(\"model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2552"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFc5JmXo41H1",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViQ7W8d-7PXK",
        "colab_type": "text"
      },
      "source": [
        "### Predict with Tensorflow Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkGzRSdA478s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the model to make predictions from our test data\n",
        "\n",
        "############################################################\n",
        "#@markdown How to use the model to predict the result with the test data (`x_test`) and save the result in a variable `predictions`?\n",
        "script = \"predictions = model.predict(x_test)\" #@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeH5sWiu7RhT",
        "colab_type": "text"
      },
      "source": [
        "### Predict with Tensorflow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET8_k-vvwop0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Use the Tensorflow lite model to make interfences from our test data\n",
        "#@markdown Please choose and fill in correct code statements from one of the following:\n",
        "#@markdown 1. interpreter.invoke() \n",
        "#@markdown 2. interpreter_input().fill(x_test[i])\n",
        "#@markdown 3. interpreter = tf.lite.Interpreter('model.tflite')\n",
        "#@markdown 4. interpreter_predictions[i] = interpreter_output()[0]\n",
        "#@markdown 5. interpreter_output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
        "#@markdown 6. interpreter_input = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])\n",
        "\n",
        "############################################################\n",
        "# Instantiate an interpreter for the TFLite model\n",
        "#@markdown Which is the statement to instantiate an interpreter with a TFLite Model named `model.tflite`?\n",
        "script_1 = \"interpreter = tf.lite.Interpreter('model.tflite')\" #@param {type:\"string\"}\n",
        "exec(script_1)\n",
        "############################################################\n",
        "\n",
        "# Allocate memory for the model\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "############################################################\n",
        "# Get the input tensors so we can feed in values \n",
        "#@markdown Which is the statement to get input sensors?\n",
        "script_2 = \"interpreter_input = interpreter.tensor(interpreter.get_input_details()[0][\\\"index\\\"])\" #@param {type:\"string\"}\n",
        "exec(script_2)\n",
        "############################################################\n",
        "\n",
        "############################################################\n",
        "# Get the output tensors so we can get the results\n",
        "#@markdown Which is the statement to get output sensors?\n",
        "script_3 = \"interpreter_output = interpreter.tensor(interpreter.get_output_details()[0][\\\"index\\\"])\" #@param {type:\"string\"}\n",
        "exec(script_3)\n",
        "############################################################\n",
        "\n",
        "# Create arrays to store the results\n",
        "interpreter_predictions = np.empty(x_test.size)\n",
        "\n",
        "# Run each model's interpreter for each value and store the results in arrays\n",
        "for i in range(x_test.size):\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to fill the input of the interpreter with `x_test[i]`?\n",
        "  script_4 = \"interpreter_input().fill(x_test[i])\" #@param {type:\"string\"}\n",
        "  exec(script_4)\n",
        "  ############################################################\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to invoke the interpreter?\n",
        "  script_5 = \"interpreter.invoke()\" #@param {type:\"string\"}\n",
        "  exec(script_5)\n",
        "  ############################################################\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to get the output from the interpreter and save the output in `interpreter_predictions[i]`?\n",
        "  script_6 = \"interpreter_predictions[i] = interpreter_output()[0]\"#@param {type:\"string\"}\n",
        "  exec(script_6)\n",
        "  ############################################################\n",
        "\n",
        "\n",
        "# Make the shape of the y_test be the same as the predictions\n",
        "y_test = np.reshape(y_test, predictions.shape)\n",
        "# Make the shape of the interpreter_predictions be the same as the predictions\n",
        "interpreter_predictions = np.reshape(interpreter_predictions, predictions.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciEdnWpc1rR5",
        "colab_type": "text"
      },
      "source": [
        "## Plot the Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svBsN_bVu1HL",
        "colab_type": "code",
        "outputId": "941738ec-d41f-4218-b67b-3aef8e13827b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.clf()\n",
        "plt.title('Test data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_test, predictions, 'r.', label='Predicted (tensorflow)')\n",
        "############################################################\n",
        "#@markdown Please write the statement to plot the outputs in green dots with a label `Predicted (tflite)` from the interpreter.\n",
        "script = \"plt.plot(x_test, interpreter_predictions, 'g.', label='Predicted (tflite)')\"#@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}